{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb347060-b2d4-4a17-8869-cade64b451e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from keras) (1.26.1)\n",
      "Requirement already satisfied: rich in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from optree->keras) (4.8.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f954ac85-f92f-4d5a-aeae-f938c6de651c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from gymnasium) (1.26.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from gymnasium) (4.8.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.17.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium[classic-control] in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from gymnasium[classic-control]) (1.26.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium[classic-control]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from gymnasium[classic-control]) (4.8.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium[classic-control]) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium[classic-control]) (7.1.0)\n",
      "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium[classic-control]) (2.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium[classic-control]) (3.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium\n",
    "!pip install gymnasium[classic-control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affiliated-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gym import wrappers\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import keras\n",
    "from keras.activations import relu, linear\n",
    "from keras.layers import Dense\n",
    "from keras import Sequential \n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from random import shuffle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d783fb49-a8da-4d82-a33c-12fcafd61f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_DIM = 2\n",
    "STATE_DIM = 4\n",
    "MAX_ITERATIONS = 200\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "GAMMA = 0.99\n",
    "REPLAY_MEMORY_SIZE = 10000\n",
    "NUM_EPISODES = 200\n",
    "MINIBATCH_SIZE = 32\n",
    "\n",
    "RANDOM_ACTION_DECAY = 0.99\n",
    "INITIAL_RANDOM_ACTION = 1\n",
    "Samples = []\n",
    "Mean = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb60b5e1-31a6-41f8-bf4f-3ebd22c5fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class replay_buffer():\n",
    "    def __init__(s, max_size):\n",
    "        s.max_size= max_size\n",
    "        s.arr = deque() # maxsize = max_size\n",
    "    \n",
    "    def add(s, val):\n",
    "        if len(s.arr) > s.max_size:\n",
    "            if (np.random.random < 0.5):\n",
    "                shuffle(s.arr)\n",
    "            s.arr.popleft()\n",
    "        s.arr.append(val)\n",
    "        \n",
    "    def sample(s, sample_size):\n",
    "        return random.sample(s.arr, sample_size)\n",
    "\n",
    "    def __len__(s):\n",
    "        return len(s.arr)\n",
    "    \n",
    "                             \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "857f5ed4-b3a7-4d34-a12d-6c71b7d7ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q(model, state):\n",
    "    np_state = np.reshape(state, [-1, STATE_DIM])\n",
    "    return model.predict(np_state, verbose = 0)\n",
    "    \n",
    "def predict(model, state):\n",
    "    np_state = np.reshape(state, [-1, STATE_DIM]) \n",
    "    return model.predict(np_state, verbose = 0)\n",
    "\n",
    "def train(model, state, targets):\n",
    "    np_state = np.reshape(state, [-1, STATE_DIM])\n",
    "    np_targets = np.reshape(targets, [-1, ACTION_DIM])\n",
    "    model.fit(np_state, np_targets, epochs = 1, verbose = 0)\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(24, input_shape = (STATE_DIM, ), activation = 'relu'))\n",
    "    model.add(Dense(24, activation = 'relu'))\n",
    "    model.add(Dense(2, activation = 'linear'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='mse',\n",
    "        metrics=[],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def update_action(action_model, target_model, samples):\n",
    "    random.shuffle(samples)\n",
    "    batch_states = []\n",
    "    batch_targets = []\n",
    "\n",
    "    for sample in samples:\n",
    "        old_state, reward, new_state, action = sample\n",
    "        targets = np.reshape(get_q(action_model, old_state), ACTION_DIM)\n",
    "        targets[action] = reward\n",
    "        if new_state is not None:\n",
    "            predictions = predict(target_model, new_state)\n",
    "            new_action = np.argmax(predictions)\n",
    "\n",
    "            targets[action] += GAMMA * predictions[0, new_action]\n",
    "\n",
    "        batch_states.append(old_state)\n",
    "        batch_targets.append(targets)\n",
    "\n",
    "    train(action_model, batch_states, batch_targets)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089a4fb2-c87e-49ca-b802-dee641ff3660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basil\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\basil\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\envs\\registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.deprecation(\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0  iteration:  24  rand_action_prob:  0.99\n",
      "episode:  1  iteration:  34  rand_action_prob:  0.9801\n",
      "episode:  2  iteration:  38  rand_action_prob:  0.9702989999999999\n",
      "episode:  3  iteration:  34  rand_action_prob:  0.96059601\n",
      "episode:  4  iteration:  15  rand_action_prob:  0.9509900498999999\n",
      "episode:  5  iteration:  13  rand_action_prob:  0.9414801494009999\n",
      "episode:  6  iteration:  31  rand_action_prob:  0.9320653479069899\n",
      "episode:  7  iteration:  19  rand_action_prob:  0.92274469442792\n",
      "episode:  8  iteration:  10  rand_action_prob:  0.9135172474836407\n",
      "episode:  9  iteration:  13  rand_action_prob:  0.9043820750088043\n",
      "episode:  10  iteration:  9  rand_action_prob:  0.8953382542587163\n",
      "episode:  11  iteration:  16  rand_action_prob:  0.8863848717161291\n",
      "episode:  12  iteration:  16  rand_action_prob:  0.8775210229989678\n",
      "episode:  13  iteration:  34  rand_action_prob:  0.8687458127689781\n",
      "episode:  14  iteration:  36  rand_action_prob:  0.8600583546412883\n",
      "episode:  15  iteration:  15  rand_action_prob:  0.8514577710948754\n",
      "episode:  16  iteration:  11  rand_action_prob:  0.8429431933839266\n",
      "episode:  17  iteration:  15  rand_action_prob:  0.8345137614500874\n",
      "episode:  18  iteration:  23  rand_action_prob:  0.8261686238355865\n",
      "episode:  19  iteration:  18  rand_action_prob:  0.8179069375972307\n",
      "episode:  20  iteration:  14  rand_action_prob:  0.8097278682212583\n",
      "episode:  21  iteration:  12  rand_action_prob:  0.8016305895390458\n",
      "episode:  22  iteration:  11  rand_action_prob:  0.7936142836436553\n",
      "episode:  23  iteration:  17  rand_action_prob:  0.7856781408072188\n",
      "episode:  24  iteration:  27  rand_action_prob:  0.7778213593991465\n",
      "episode:  25  iteration:  9  rand_action_prob:  0.7700431458051551\n",
      "episode:  26  iteration:  8  rand_action_prob:  0.7623427143471035\n",
      "episode:  27  iteration:  10  rand_action_prob:  0.7547192872036325\n",
      "episode:  28  iteration:  36  rand_action_prob:  0.7471720943315961\n",
      "episode:  29  iteration:  8  rand_action_prob:  0.7397003733882802\n",
      "episode:  30  iteration:  9  rand_action_prob:  0.7323033696543974\n",
      "episode:  31  iteration:  19  rand_action_prob:  0.7249803359578534\n",
      "episode:  32  iteration:  18  rand_action_prob:  0.7177305325982748\n",
      "episode:  33  iteration:  11  rand_action_prob:  0.7105532272722921\n",
      "episode:  34  iteration:  28  rand_action_prob:  0.7034476949995692\n",
      "episode:  35  iteration:  30  rand_action_prob:  0.6964132180495735\n",
      "episode:  36  iteration:  19  rand_action_prob:  0.6894490858690777\n",
      "episode:  37  iteration:  19  rand_action_prob:  0.682554595010387\n",
      "episode:  38  iteration:  40  rand_action_prob:  0.6757290490602831\n",
      "episode:  39  iteration:  25  rand_action_prob:  0.6689717585696803\n",
      "episode:  40  iteration:  10  rand_action_prob:  0.6622820409839835\n",
      "episode:  41  iteration:  8  rand_action_prob:  0.6556592205741436\n",
      "episode:  42  iteration:  20  rand_action_prob:  0.6491026283684022\n",
      "episode:  43  iteration:  19  rand_action_prob:  0.6426116020847181\n",
      "episode:  44  iteration:  21  rand_action_prob:  0.6361854860638709\n",
      "episode:  45  iteration:  10  rand_action_prob:  0.6298236312032323\n",
      "episode:  46  iteration:  28  rand_action_prob:  0.6235253948912\n",
      "episode:  47  iteration:  9  rand_action_prob:  0.617290140942288\n",
      "episode:  48  iteration:  25  rand_action_prob:  0.6111172395328651\n",
      "episode:  49  iteration:  21  rand_action_prob:  0.6050060671375365\n",
      "episode:  50  iteration:  18  rand_action_prob:  0.5989560064661611\n",
      "episode:  51  iteration:  7  rand_action_prob:  0.5929664464014994\n",
      "episode:  52  iteration:  42  rand_action_prob:  0.5870367819374844\n",
      "episode:  53  iteration:  7  rand_action_prob:  0.5811664141181095\n",
      "episode:  54  iteration:  19  rand_action_prob:  0.5753547499769285\n",
      "episode:  55  iteration:  12  rand_action_prob:  0.5696012024771592\n",
      "episode:  56  iteration:  10  rand_action_prob:  0.5639051904523876\n",
      "episode:  57  iteration:  27  rand_action_prob:  0.5582661385478638\n",
      "episode:  58  iteration:  7  rand_action_prob:  0.5526834771623851\n",
      "episode:  59  iteration:  23  rand_action_prob:  0.5471566423907612\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(replay) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m MINIBATCH_SIZE \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.25\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m Samples[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m195\u001b[39m:\n\u001b[0;32m     51\u001b[0m             minibatch \u001b[38;5;241m=\u001b[39m replay\u001b[38;5;241m.\u001b[39msample(MINIBATCH_SIZE)\n\u001b[1;32m---> 52\u001b[0m             \u001b[43mupdate_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminibatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m, in \u001b[0;36mupdate_action\u001b[1;34m(action_model, target_model, samples)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples:\n\u001b[0;32m     34\u001b[0m     old_state, reward, new_state, action \u001b[38;5;241m=\u001b[39m sample\n\u001b[1;32m---> 35\u001b[0m     targets \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(\u001b[43mget_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_state\u001b[49m\u001b[43m)\u001b[49m, ACTION_DIM)\n\u001b[0;32m     36\u001b[0m     targets[action] \u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m, in \u001b[0;36mget_q\u001b[1;34m(model, state)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_q\u001b[39m(model, state):\n\u001b[0;32m      2\u001b[0m     np_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(state, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, STATE_DIM])\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:501\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    499\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    502\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m    503\u001b[0m         data \u001b[38;5;241m=\u001b[39m get_data(iterator)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:645\u001b[0m, in \u001b[0;36mTFEpochIterator.enumerate_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 645\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches:\n\u001b[0;32m    647\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[0;32m    648\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution\n\u001b[0;32m    649\u001b[0m         ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:705\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    701\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 705\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:744\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    741\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    742\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    743\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 744\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3479\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Temp = []\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "rand_action_prob = INITIAL_RANDOM_ACTION\n",
    "\n",
    "replay = replay_buffer(REPLAY_MEMORY_SIZE)\n",
    "\n",
    "action_model = get_model()\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "for episode in range(NUM_EPISODES):\n",
    "    if np.mean(Temp) > 195 and cnt > 195:\n",
    "        print('PASSED!')\n",
    "        break\n",
    "\n",
    "    rand_action_prob *= RANDOM_ACTION_DECAY\n",
    "    new_state, info = env.reset(seed = 42)\n",
    "\n",
    "    for iteration in range(MAX_ITERATIONS):\n",
    "        rand_action_prob = max(rand_action_prob, 0.1)\n",
    "        old_state = new_state\n",
    "        if np.random.random() < rand_action_prob:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            q_values = get_q(action_model, old_state)\n",
    "            sction = q_values.argmax()\n",
    "\n",
    "        new_state, reward, terminated, done, info = env.step(action)\n",
    "\n",
    "        if done or terminated:\n",
    "            Samples.append(iteration+1)\n",
    "            if (len(Samples) > 50):\n",
    "                Temp = Samples[-50:] # select most recent 50\n",
    "                Mean.append(np.mean(Samples[-20:]))\n",
    "            \n",
    "            print('episode: ', episode, ' iteration: ', iteration, ' rand_action_prob: ', rand_action_prob)\n",
    "\n",
    "            if iteration != 199:\n",
    "                reward = -5\n",
    "            if iteration == 199:\n",
    "                reward = 5\n",
    "            replay.add((old_state, reward, None, action))\n",
    "            break # and start game again\n",
    "\n",
    "        replay.add((old_state, reward, new_state, action))\n",
    "\n",
    "        # update model\n",
    "        if len(replay) >= MINIBATCH_SIZE and np.random.random() < 0.25 and Samples[-1] < 195:\n",
    "            minibatch = replay.sample(MINIBATCH_SIZE)\n",
    "            update_action(action_model, action_model, minibatch)\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "env.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f319134-b55f-4df8-872d-302020f0e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode = 'human')\n",
    "Tests = []\n",
    "for i in range(10):\n",
    "    prev_state, info = env.reset()\n",
    "    terminated = False\n",
    "    done = False\n",
    "    cnt = 0\n",
    "    while not terminated and not done:\n",
    "        q_valus = get_q(action_model, prev_state)\n",
    "        action = q_values.argmax()\n",
    "        state, reward, terminated, done, info = env.step(action)\n",
    "        if done:\n",
    "            Tests.append(cnt)\n",
    "            break\n",
    "        cnt+=1\n",
    "        prev_state = state\n",
    "        \n",
    "env.close()\n",
    "\n",
    "plt.plot(Tests)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
