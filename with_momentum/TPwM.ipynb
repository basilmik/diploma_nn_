{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa1c7b5-8a91-4a55-80f1-3e92beef3b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad536855-8dd3-4cad-8ddb-c4fdbac5bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(x):\n",
    "    res = 1 / (1 + np.exp(-x))\n",
    "    return res\n",
    "\n",
    "def d_Sigmoid(x):\n",
    "    y = Sigmoid(x) * (1 - Sigmoid(x))\n",
    "    return y\n",
    "\n",
    "def ReLU(x):\n",
    "    x = np.maximum(0, x)\n",
    "    return x\n",
    "    \n",
    "def d_ReLU(x):\n",
    "    y=x.copy()\n",
    "    y[y<=0] = 0\n",
    "    y[y>0] = 1\n",
    "    return y\n",
    "\n",
    "\n",
    "def Linear(x):\n",
    "    return x\n",
    "\n",
    "def d_Linear(x):\n",
    "    y = np.ones(shape=(x.shape), dtype = x.dtype)\n",
    "    return y\n",
    "\n",
    "activations_dict = {\n",
    "'Sigmoid': [Sigmoid, d_Sigmoid],\n",
    "'ReLU': [ReLU, d_ReLU], \n",
    "'Linear': [Linear, d_Linear]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0c9571-2702-416f-b3f6-3a202873fb3a",
   "metadata": {},
   "source": [
    "## input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11960885-56e4-42ee-9271-3141c226f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class input_layer:\n",
    "    def __init__(s, size):\n",
    "        s.size = size\n",
    "        #s.values = np.zeros(shape=(size), dtype = float)\n",
    "    \n",
    "    def add_neuron(s):\n",
    "        #add_v = np.zeros(shape=(n_of_neurons), dtype=float)\n",
    "        #s.values = np.concatenate((s.values, add_v.T))\n",
    "        s.size += 1\n",
    "\n",
    "    def delete_neuron(s, neuron_number):\n",
    "        s.size-=1\n",
    "        \n",
    "    def delete_new_prev_size(s):     \n",
    "        return\n",
    "\n",
    "\n",
    "    def add_new_prev_size(s):     \n",
    "        return\n",
    "\n",
    "        \n",
    "    def print_info(s):\n",
    "        print(\"IN LAYER\\nsize: \", s.size)\n",
    "\n",
    "    \n",
    "    def print_pic(s):\n",
    "        print_size = min(2, s.size)\n",
    "\n",
    "        for i in range(print_size): \n",
    "            print(\"| |\\t\", end='')\n",
    "        print(\"\")\n",
    "        for i in range(print_size):\n",
    "            print(\" v \\t\", end='')\n",
    "        print(\"\")\n",
    "        for i in range(print_size):\n",
    "            print(' @\\t', end='')\n",
    "        print (\"--\", format(s.size, ' 5d') , \"--\\t\", end='')\n",
    "\n",
    "    def forward(s, x, to_print = False):\n",
    "        s.values = x\n",
    "        return x\n",
    "        \n",
    "    def forward_nu(s, x):\n",
    "        return x\n",
    "\n",
    "    def get_info(s):\n",
    "        return s.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe0c956-c5d1-4c97-a5c1-f9834d29b162",
   "metadata": {},
   "source": [
    "## layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42278612-f311-452d-93eb-c6ce6785a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(s, lr = 0.1, prev_size = 2, my_size=2, activation_type = \"Sigmoid\", weights = None, bias = None):\n",
    "        s.lr = lr\n",
    "        s.size = my_size\n",
    "        s.prev_size = prev_size\n",
    "        if (np.all(weights == None)):\n",
    "            # s.weights = np.random.random((prev_size, s.size))\n",
    "            s.w = np.random.random((s.size, prev_size))\n",
    "        else:\n",
    "            s.w = weights.copy()\n",
    "            \n",
    "        if (np.all(bias == None)):\n",
    "            s.b = np.random.random((s.size, 1))\n",
    "        else:\n",
    "            s.b = bias.copy()\n",
    "            \n",
    "        s.activation_type = activation_type\n",
    "        funcs = activations_dict.get(activation_type)\n",
    "        s.activation_f = funcs[0]\n",
    "        s.d_activation_f = funcs[1]\n",
    "        s.Vdw = np.zeros(shape=(s.size, prev_size))\n",
    "        s.Vdb = np.zeros(shape=(s.size, 1))\n",
    "\n",
    "\n",
    "    def activate(s, x):\n",
    "        return s.activation_f(x)\n",
    "        \n",
    "    def d_activate(s, x):\n",
    "        return s.d_activation_f(x)  \n",
    "\n",
    "    \n",
    "    def forward(s, x, to_print = False):\n",
    "        s.x = np.asarray(x)\n",
    "        s.z = np.dot(s.w, s.x) + s.b\n",
    "        \n",
    "        if (to_print): \n",
    "            print('wT * x + b', s.z)\n",
    "\n",
    "        s.a = s.activate(s.z)\n",
    "\n",
    "        if (to_print): \n",
    "            print('s.a ',s.a)\n",
    "            \n",
    "        return s.a\n",
    "\n",
    "    def backprop(s, da):\n",
    "        s.dz = da * s.d_activate(s.z)\n",
    "        s.da_ = np.dot(s.w.T, s.dz) \n",
    "\n",
    "        \n",
    "        return s.da_\n",
    "        \n",
    "    def update_weights(s, optimizer = \"SGD\", beta = 0.9):\n",
    "        \n",
    "        m = s.x.shape[1]\n",
    "        if (optimizer == \"SGD\"):\n",
    "            \n",
    "            s.dw = (1/m)*np.dot(s.dz, s.x.T)\n",
    "            s.db = (1/m)*np.sum(s.dz, axis = 1, keepdims = True)\n",
    "    \n",
    "            s.w = s.w - s.lr * s.dw\n",
    "            s.b = s.b - s.lr * s.db\n",
    "            \n",
    "        elif (optimizer==\"SGDwM\"):\n",
    "            \n",
    "            # s.input_t = s.input.T\n",
    "            # #print(s.input_t.shape[1])\n",
    "            # s.x = s.input_t #.reshape((s.input_t.shape[0], 1))\n",
    "            # s.d = s.delta#.reshape((1, s.delta.shape[0]))\n",
    "            \n",
    "            # dw = np.dot(s.x, s.d)\n",
    "            # db = s.delta\n",
    "            \n",
    "            s.dw = (1/m)*np.dot(s.dz, s.x.T)\n",
    "            s.db = (1/m)*np.sum(s.dz, axis = 1, keepdims = True)\n",
    "\n",
    "            s.Vdw = beta * s.Vdw + (1 - beta)*s.dw\n",
    "            s.Vdb = beta * s.Vdb + (1 - beta)*s.db\n",
    "            \n",
    "            s.w = s.w - s.lr * s.Vdw\n",
    "            s.b = s.b - s.lr * s.Vdb\n",
    "\n",
    "        else:\n",
    "            print(\"NO SUCH OPTIMIZER!\")\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "            \n",
    "        \n",
    "    def print_info(s):\n",
    "        print(\"my size: \", s.size)\n",
    "        print(\"w: \", s.weights, \"\\n\")\n",
    "        print(\"b: \", s.bias, \"\\n\")\n",
    "\n",
    "              \n",
    "    def print_pic(s):\n",
    "        print_size = min(2, s.size)\n",
    "        print(\"\\nâ•»...\\nv...\")\n",
    "        for i in range(print_size):\n",
    "            print('O\\t', end='')\n",
    "        print (\"--\", format(s.size, ' 5d') , \"--\\t\", end='')\n",
    "\n",
    "\n",
    "\n",
    "    def correct_prev_size(s, new_prev_szie):\n",
    "        dif = new_prev_szie - s.prev_size\n",
    "        if dif > 0: # new prev is greater\n",
    "            for i in range(dif):\n",
    "                s.add_new_prev_size()\n",
    "        elif dif < 0:\n",
    "            dif*=-1\n",
    "            for i in range(dif):\n",
    "                s.delete_new_prev_size()\n",
    "        s.prev_size = new_prev_szie\n",
    "\n",
    "\n",
    "    def delete_neuron(s, neuron_number):\n",
    "        s.weights = np.delete(s.weights, neuron_number, axis = 1)\n",
    "        s.bias = np.delete(s.bias, neuron_number, axis = 0)\n",
    "        s.size-=1\n",
    "        \n",
    "    def delete_new_prev_size(s):     \n",
    "        s.weights = np.delete(s.weights, 0, axis = 0)\n",
    "        s.prev_size -=1\n",
    "\n",
    "\n",
    "    def add_neuron(s):     \n",
    "        add_w = np.zeros(shape=(s.prev_size, 1), dtype=float) + 0.1 # np.random.random((s.prev_size, n_of_neurons)) #\n",
    "        s.weights = np.concatenate((s.weights.T, add_w.T)).T\n",
    "        add_b = np.zeros(shape=(1), dtype=float) + 0.1 \n",
    "        s.bias = np.concatenate((s.bias, add_b))\n",
    "        s.size+=1\n",
    "\n",
    "    def add_new_prev_size(s):     \n",
    "        add_w = np.zeros(shape=(1, s.size), dtype=float) + 0.1\n",
    "        s.weights = np.concatenate((s.weights, add_w))\n",
    "        s.prev_size += 1\n",
    "\n",
    "    def get_info(s):\n",
    "        return s.prev_size, s.size, s.weights, s.bias, s.activation_type, s.lr\n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae710b4e-f290-48ea-b91a-3cf97dd926f2",
   "metadata": {},
   "source": [
    "## plastic nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b5958be-6ee5-4b92-9c34-7a695b81f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class plastic_nn:\n",
    "    def __init__(s, optimizer = \"SGD\", beta = 0.9):\n",
    "        s.layers = []\n",
    "        s.n_of_layers = 0\n",
    "        s.name = 'noname'\n",
    "        s.optimizer = optimizer\n",
    "        s.beta = beta\n",
    "        pass\n",
    "\n",
    "    def give_name(s, name):\n",
    "        s.name = name\n",
    "        \n",
    "    def set_num_of_layers(s, num):\n",
    "        s.n_of_layers = num\n",
    "        \n",
    "    def deep_copy(s):\n",
    "        return copy.deepcopy(s)\n",
    "\n",
    "    \n",
    "    def forward(s, x, to_print = False):\n",
    "        for lay in s.layers:\n",
    "            x = lay.forward(x, to_print)\n",
    "        s.last_result = x\n",
    "        return s.last_result\n",
    "        \n",
    "    def forward_print(s, x, to_print = False):\n",
    "        print('in: ',data)\n",
    "        cnt = 0\n",
    "        for lay in s.layers:\n",
    "            x = lay.forward(x, to_print)\n",
    "            print(cnt, ' ', x)\n",
    "            cnt+=1\n",
    "        s.last_result = x\n",
    "        return s.last_result\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def backprop(s, correct):\n",
    "        m = correct.shape[1]\n",
    "        err = (1/m)*(s.last_result - correct) # a - y\n",
    "        cnt = 0\n",
    "        for lay in reversed(s.layers[1:]):\n",
    "            #print(cnt)\n",
    "            err = lay.backprop(err)\n",
    "            cnt+=1\n",
    "\n",
    "    def backprop_error(s, err):\n",
    "        for lay in reversed(s.layers[1:]):\n",
    "            err = lay.backprop(err)\n",
    "\n",
    "    def update(s):\n",
    "        i = 0\n",
    "        for lay in reversed(s.layers[1:]):\n",
    "            #print('layer idx: ', i)\n",
    "            i+=1\n",
    "            lay.update_weights(s.optimizer,s.beta)\n",
    "            #print('\\n')\n",
    "\n",
    "\n",
    "    \n",
    "    def learn_one(s, in_data, target_data):\n",
    "        s.forward(in_data)\n",
    "        s.backprop(target_data)\n",
    "        s.update()   \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def append_one(s, new_layer, check = False):\n",
    "        if check and s.n_of_layers!=0:\n",
    "            last_layer_size = s.layers[-1].size\n",
    "            if last_layer_size != new_layer.prev_size:\n",
    "                print(\"size not match, layer \", s.n_of_layers)\n",
    "                return\n",
    "        s.layers.append(new_layer)\n",
    "        s.n_of_layers+=1\n",
    "        return\n",
    "\n",
    "    def check_layers_sizes(s, check_layers):\n",
    "        for i in range(1, len(check_layers)):\n",
    "            if (check_layers[i-1].size != check_layers[i].prev_size):\n",
    "                print(\"error between \", i-1, \"and \", i)\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    \n",
    "    def append_layers(s, new_layers):\n",
    "        test_layers = np.array([])\n",
    "        if s.n_of_layers != 0: # if has layers\n",
    "            test_layers = s.layers[-1] # get last layers\n",
    "        \n",
    "        test_layers = np.append(test_layers, new_layers) \n",
    "                \n",
    "        if (s.check_layers_sizes(test_layers)):\n",
    "            for lay in new_layers:\n",
    "                s.append_one(lay)\n",
    "            print(\"added LAYERS succesfully\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"ERROR adding layers, check info above\")\n",
    "            return False\n",
    "\n",
    "    def add_layer_by_pos(s, pos, new_layer):\n",
    "        if (pos <= 0 or pos > s.n_of_layers): # if input or more than 'to last'\n",
    "            print(\"ERROR addning layer: invalid layer number!\")\n",
    "            if (pos == 0):\n",
    "                print(\"input layer cannot be replaced by different layer\")\n",
    "            return\n",
    "            \n",
    "        if (pos == s.n_of_layers): # if add to the last\n",
    "            s.append(new_layer)\n",
    "            return\n",
    "            \n",
    "        if (new_layer.prev_size!=s.layers[pos-1].size):\n",
    "            print(\"ERROR addning layer: invalid prev_size!\")\n",
    "            return \n",
    "            \n",
    "        s.layers.insert(pos, new_layer)\n",
    "        prev_size = new_layer.size\n",
    "        \n",
    "        # update next layer prev_size and w matrix\n",
    "        next_lay = s.layers[pos+1]\n",
    "        next_lay.correct_prev_size(prev_size)\n",
    "        s.n_of_layers += 1\n",
    "\n",
    "    def delete_layer_by_pos(s, pos):\n",
    "        if (pos <= 0 or pos >= s.n_of_layers): # if input or more than 'to last'\n",
    "            print(\"ERROR deleting layer: invalid layer number!\")\n",
    "            if (pos == 0):\n",
    "                print(\"input layer cannot be deleted\")\n",
    "            return\n",
    "        \n",
    "        new_prev_size = s.layers[pos].prev_size \n",
    "        if (pos != s.n_of_layers-1): #if not last\n",
    "            next_lay = s.layers[pos+1]\n",
    "            next_lay.correct_prev_size(new_prev_size)\n",
    "\n",
    "        del s.layers[pos]\n",
    "        s.n_of_layers -= 1\n",
    "\n",
    "\n",
    "    def add_neuron(s, layer_number, n_of_neurons = 1):\n",
    "        if (layer_number < 0 or layer_number>= s.n_of_layers):\n",
    "            print(\"ERROR addning neuron: invalid layer number!\")\n",
    "            return\n",
    "        \n",
    "        main_lay = s.layers[layer_number]  \n",
    "        \n",
    "        for i in range(n_of_neurons):\n",
    "            main_lay.add_neuron()           \n",
    "            if (layer_number+1 != s.n_of_layers): # if main is not last\n",
    "                # update next layer prev_size and w matrix\n",
    "                next_lay = s.layers[layer_number+1]\n",
    "                next_lay.add_new_prev_size()\n",
    "    \n",
    "    def delete_neuron(s, layer_number, neuron_number):\n",
    "        if (layer_number < 0 or layer_number>= s.n_of_layers):\n",
    "            print(\"ERROR deleting neuron: invalid layer number!\")\n",
    "            return\n",
    "            \n",
    "        main_lay = s.layers[layer_number] \n",
    "        \n",
    "        if (neuron_number >= main_lay.size):\n",
    "            print(\"ERROR deleting neuron: invalid neuron number!\")\n",
    "            return\n",
    "\n",
    "        main_lay.delete_neuron(neuron_number)\n",
    "        if (layer_number+1 != s.n_of_layers): # if main is not last\n",
    "                # update next layer prev_size and w matrix\n",
    "                next_lay = s.layers[layer_number+1]\n",
    "                next_lay.delete_new_prev_size()\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def print_info(s):\n",
    "        print('NAME: ', s.name, ' (', s.n_of_layers, ')')\n",
    "        for cnt in range(s.n_of_layers):\n",
    "            print(\"#\", cnt)\n",
    "            s.layers[cnt].print_info()\n",
    "            print(\"\")\n",
    "    \n",
    "    def print_pic(s):\n",
    "        print('NAME: ', s.name, ' (', s.n_of_layers, ')')\n",
    "        cnt = 0\n",
    "        for lay in s.layers:\n",
    "            lay.print_pic()\n",
    "            print(\"#\", cnt, end='')\n",
    "            cnt+=1\n",
    "        print(\"\\nOUT |#|\\nOUT  v\")\n",
    "\n",
    "    \n",
    "    def save(s, file_path):       \n",
    "        f = open(file_path, \"w\").close()\n",
    "        \n",
    "        f = open(file_path, \"a\")       \n",
    "        f.write(\"{}\\n{}\\n\".format(s.name, s.n_of_layers))       \n",
    "        input_layer_size = s.layers[0].get_info()\n",
    "        f.write(\"{}\\n\".format(input_layer_size))\n",
    "\n",
    "        for lay in s.layers[1:]:            \n",
    "            prev_size, size, weights, bias, activation_type, lr = lay.get_info()\n",
    "            f.write(\"{}\\n\".format(prev_size))\n",
    "            f.write(\"{}\\n\".format(size))\n",
    "            \n",
    "            np.savetxt(f, weights)#, fmt='%f')\n",
    "            np.savetxt(f, bias)#, fmt='%f')\n",
    "            f.write(\"{}\\n\".format(activation_type))\n",
    "            f.write(\"{}\\n\".format(lr))\n",
    "                 \n",
    "        f.close()\n",
    "\n",
    "        \n",
    "    def load(s, file_path):\n",
    "        s.layers = None\n",
    "        s.layers = []\n",
    "        s.n_of_layers = 0       \n",
    "        layers = []\n",
    "        f = open(file_path, \"r\")       \n",
    "        name = f.readline().split()[0]\n",
    "        total_n_of_layers = int(f.readline().split()[0])\n",
    "        input_layer_size = int(f.readline().split()[0])\n",
    "\n",
    "        in_layer = input_layer(input_layer_size)\n",
    "        layers.append(in_layer)\n",
    "        \n",
    "        s.give_name(name)\n",
    "\n",
    "        for i in range(total_n_of_layers-1):\n",
    "            prev_size = int(f.readline().split()[0])\n",
    "            size = int(f.readline().split()[0])\n",
    "            weights = np.loadtxt(f, max_rows = prev_size)\n",
    "            bias = np.loadtxt(f, max_rows = size)\n",
    "            activation_type = f.readline().split()[0]\n",
    "            lr = float(f.readline().split()[0])\n",
    "\n",
    "            layers.append(layer(lr = lr, prev_size= prev_size, my_size = size, \n",
    "                                activation_type = activation_type, weights = weights, bias = bias))\n",
    "            \n",
    "        s.append(layers)             \n",
    "        f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "752d5b3e-90de-4a3f-b869-d554c2ceae03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "t [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "w [[0.4558009  0.88344769 0.42685618]\n",
      " [0.83669572 0.94891773 0.32331695]\n",
      " [0.65285077 0.79953679 0.51855946]\n",
      " [0.42978998 0.46442386 0.38900787]\n",
      " [0.49510835 0.01702194 0.42035954]]\n",
      "z [[0.64005794]\n",
      " [1.26417282]\n",
      " [0.69679247]\n",
      " [0.49254575]\n",
      " [1.09640177]]\n",
      "a [[0.65476656]\n",
      " [0.7797436 ]\n",
      " [0.66747624]\n",
      " [0.62070596]\n",
      " [0.7495853 ]]\n",
      "e [[-0.34523344]\n",
      " [-0.2202564 ]\n",
      " [-0.33252376]\n",
      " [-0.37929404]\n",
      " [-0.2504147 ]]\n",
      "dz [[-0.07803909]\n",
      " [-0.03782761]\n",
      " [-0.07380422]\n",
      " [-0.08929722]\n",
      " [-0.04700464]]\n",
      "dw [[-0.01082564 -0.04166915 -0.00783803]\n",
      " [-0.00524747 -0.02019814 -0.0037993 ]\n",
      " [-0.01023817 -0.03940793 -0.00741269]\n",
      " [-0.01238737 -0.04768045 -0.00896876]\n",
      " [-0.00652052 -0.02509823 -0.00472101]]\n",
      "db [[-0.07803909]\n",
      " [-0.03782761]\n",
      " [-0.07380422]\n",
      " [-0.08929722]\n",
      " [-0.04700464]]\n",
      "da_ [[-0.17705507]\n",
      " [-0.2061198 ]\n",
      " [-0.13830982]]\n"
     ]
    }
   ],
   "source": [
    "output_size = 5\n",
    "input_size = 3\n",
    "\n",
    "\n",
    "m = 1\n",
    "x = np.random.random((input_size, m))\n",
    "print(x.shape)\n",
    "target =  np.ones((output_size, m))\n",
    "print('t', target)\n",
    "\n",
    "w = np.random.random((output_size, input_size))\n",
    "print('w', w)\n",
    "\n",
    "b = np.random.random((output_size, 1))\n",
    "#print(b)\n",
    "\n",
    "z = np.dot(w, x) + b\n",
    "print('z', z)\n",
    "\n",
    "a = Sigmoid(z)\n",
    "print('a', a)\n",
    "last_res = a\n",
    "\n",
    "\n",
    "\n",
    "s = target.shape[1] \n",
    "err = (1/s) * (last_res - target)\n",
    "print('e', err)\n",
    "\n",
    "dz = err * d_Sigmoid(z)\n",
    "print('dz', dz)\n",
    "\n",
    "# dw = dz*x.T\n",
    "dw = (1/s)*np.dot(dz, x.T)\n",
    "print('dw', dw)\n",
    "\n",
    "db = (1/s) * np.sum(dz, axis = 1, keepdims = True)\n",
    "print('db', db)\n",
    "\n",
    "da_ = np.dot(w.T, dz) \n",
    "print('da_', da_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da26954e-f189-47dc-b7ef-f322cd9aab40",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bea2c76f-7f02-493a-9ea9-43c8d8ad6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c594363-edf1-4a22-8c56-af21ac08eb07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added LAYERS succesfully\n",
      "[ ------------------------- * ------------------------ ]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'error')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "train_size = 512\n",
    "data_x_offset = 20\n",
    "data_y_offset = 20\n",
    "in_data = [] \n",
    "target_data = []\n",
    "for i in range(train_size):\n",
    "    theta = np.random.random() * 2 * math.pi\n",
    "    radius = np.random.rand() * 0.3\n",
    "    if (i < train_size/4):\n",
    "        in_data.append([0 + radius*math.cos(theta), 0 + radius*math.sin(theta) ])\n",
    "        target_data.append([0])\n",
    "    elif (i < 2*train_size/4):\n",
    "        in_data.append([1 + radius*math.cos(theta), 1 + radius*math.sin(theta) ])\n",
    "        target_data.append([0])\n",
    "    elif(i < 3*train_size/4):\n",
    "        in_data.append([ 1 + radius*math.cos(theta), 0 + radius*math.sin(theta) ])\n",
    "        target_data.append([1])\n",
    "    else:\n",
    "        in_data.append([ 0 + radius*math.cos(theta), 1 + radius*math.sin(theta) ])\n",
    "        target_data.append([1])\n",
    "\n",
    "test_size = round(train_size*0.2)\n",
    "in_test_data = [] \n",
    "target_test_data = []\n",
    "for i in range(test_size):\n",
    "    theta = np.random.random() * 2 * math.pi\n",
    "    radius = np.random.rand() * 0.3\n",
    "    if (i < test_size/4):\n",
    "        in_test_data.append([0 + radius*math.cos(theta), 0 + radius*math.sin(theta) ])\n",
    "        target_test_data.append([0])\n",
    "    elif (i < 2*test_size/4):\n",
    "        in_test_data.append([1 + radius*math.cos(theta), 1 + radius*math.sin(theta) ])\n",
    "        target_test_data.append([0])\n",
    "    elif(i < 3*test_size/4):\n",
    "        in_test_data.append([ 1 + radius*math.cos(theta), 0 + radius*math.sin(theta) ])\n",
    "        target_test_data.append([1])\n",
    "    else:\n",
    "        in_test_data.append([ 0 + radius*math.cos(theta), 1 + radius*math.sin(theta) ])\n",
    "        target_test_data.append([1])\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(np.array(in_data)[:, 0], np.array(in_data)[:, 1], c = target_data)\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "# plt.title(\"training data\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(np.array(in_test_data)[:, 0], np.array(in_test_data)[:, 1], c = target_test_data)\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "# plt.title(\"validation data\")\n",
    "\n",
    "\n",
    "in_layer = input_layer(2)\n",
    "tl = layer(lr = 0.01, prev_size = 2, my_size=2, activation_type=\"ReLU\")#, optimizer = 'SGD', beta = 0.8)\n",
    "out_layer = layer(lr = 0.01, prev_size = 2, my_size=1, activation_type=\"Sigmoid\")#, optimizer = 'SGD', beta = 0.6)\n",
    "\n",
    "test_nn = plastic_nn(\"SGDwM\")\n",
    "layers = [in_layer, tl, out_layer]\n",
    "\n",
    "test_nn.append_layers(layers)\n",
    "\n",
    "\n",
    "\n",
    "to_display_bar = True\n",
    "\n",
    "graph_err = []\n",
    "graph_epoch=[]\n",
    "epochs = 2\n",
    "target_data = np.array(target_data)\n",
    "#print(target_data)\n",
    "\n",
    "bar_len = 50\n",
    "\n",
    "def display_bar(bar_len, idx, total):\n",
    "    idx = int(idx*bar_len/total)\n",
    "    #print(perc)\n",
    "    print(\"[\", \"-\"*idx, \"*\", \"-\"*(bar_len-idx-1), \"]\", end='')\n",
    "    print(\"\\r\",end='')\n",
    "    \n",
    "in_data = np.asarray(in_data)\n",
    "minibatch_size = 1\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "#in_data, target_data = unison_shuffled_copies(in_data, target_data)\n",
    "for i in range(epochs):\n",
    "    if to_display_bar:\n",
    "        display_bar(bar_len, i, epochs)\n",
    "\n",
    "    for idx in range(int(len(in_data)/minibatch_size)):\n",
    "\n",
    "        \n",
    "        x = np.asarray(in_data[idx*minibatch_size:(idx+1)*minibatch_size])\n",
    "        #x = x.reshape(x.shape[0], minibatch_size)\n",
    "        #print(x.T.shape)\n",
    "        y = np.asarray(target_data[idx*minibatch_size:(idx+1)*minibatch_size])\n",
    "        #y = np.asarray(target_data[i])\n",
    "        #y = y.reshape(y.shape[0], minibatch_size)\n",
    "        #print(y.T.shape)\n",
    "        \n",
    "        test_nn.learn_one(x.T, y.T)\n",
    "        #test_nn.learn_one(x, y)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    error_sum = 0\n",
    "    for idx in range(len(in_test_data)):#1):#\n",
    "        y = np.asarray(in_test_data[idx])\n",
    "        y = y.reshape(y.shape[0], 1)\n",
    "        #print(y.shape)\n",
    "        valid_res = test_nn.forward(y)\n",
    "        #print(target_test_data[idx])\n",
    "        #print(valid_res)\n",
    "        error = (target_test_data[idx] - valid_res)**2\n",
    "        error_sum+=error\n",
    "    \n",
    "    graph_err.append(error_sum/len(in_test_data))\n",
    "    graph_epoch.append(i)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(graph_epoch, graph_err)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff266791-3933-40e4-a4e3-c575dbe10a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2)\n",
      "[[0.69940035]]\n",
      "[[0.80437358]]\n",
      "[[0.77997279]]\n",
      "[[0.86234689]]\n",
      "[[0.72821758]]\n",
      "[[0.79766284]]\n",
      "[[0.77741632]]\n",
      "[[0.87826211]]\n"
     ]
    }
   ],
   "source": [
    "test_2_in = [[0, 0], [0,1], [1, 0], [1, 1],\n",
    "            [0.2, 0.1], [-0.1, 1], [1.1, -0.1], [1.2, 1.1]]\n",
    "test_2_in = np.asarray(test_2_in)\n",
    "print(test_2_in.shape)\n",
    "for i in range(len(test_2_in)):\n",
    "    y = test_2_in[i]\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "    print(test_nn.forward(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c0443d3-0409-4eab-9abd-47a49a875314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2)\n",
      "[[0.08003269]]\n",
      "[[0.98405072]]\n",
      "[[0.97880336]]\n",
      "[[0.03533862]]\n",
      "[[0.29832271]]\n",
      "[[0.96918459]]\n",
      "[[0.97819374]]\n",
      "[[0.00359638]]\n"
     ]
    }
   ],
   "source": [
    "test_2_in = [[0, 0], [0,1], [1, 0], [1, 1],\n",
    "            [0.2, 0.1], [-0.1, 1], [1.1, -0.1], [1.2, 1.1]]\n",
    "test_2_in = np.asarray(test_2_in)\n",
    "print(test_2_in.shape)\n",
    "for i in range(len(test_2_in)):\n",
    "    y = test_2_in[i]\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "    print(test_nn.forward(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4ebdafd9-b304-497d-b7d7-297287604aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2752312456714689, 0.001211673707697106]\n",
      "[[0.50741724]]\n",
      "[-0.17333492893847446, -0.2042900582853883]\n",
      "[[0.49783411]]\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(in_test_data[10])):#1):#\n",
    "    print(in_test_data[idx])\n",
    "    y = np.asarray(in_test_data[idx])\n",
    "    y = y.reshape(y.shape[0], 1)\n",
    "    #print(y.shape)\n",
    "    valid_res = test_nn.forward(y)\n",
    "    print(valid_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
