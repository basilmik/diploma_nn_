{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e71df1-03b0-4aac-a5b9-431ddd4e4e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from gymnasium) (1.26.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from gymnasium) (4.8.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad4b8fe-efc9-49c3-852e-d7a0afd40543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 [ 4 12 12  2]\n",
      "Best rewards so far: 17.0\n",
      "Best rewards so far: 23.0\n",
      "Best rewards so far: 31.0\n",
      "Best rewards so far: 32.0\n",
      "Best rewards so far: 52.0\n",
      "Best rewards so far: 63.0\n",
      "Best rewards so far: 64.0\n",
      "Best rewards so far: 90.0\n",
      "Best rewards so far: 99.0\n",
      "Episode 1000 Epsilon 0.900300000000011\n",
      "Best rewards so far: 129.0\n",
      "Episode 2000 Epsilon 0.800300000000022\n",
      "Episode 3000 Epsilon 0.700300000000033\n",
      "Episode 4000 Epsilon 0.600300000000044\n",
      "Episode 5000 Epsilon 0.500300000000055\n",
      "Episode 6000 Epsilon 0.40030000000006605\n",
      "Best rewards so far: 202.0\n",
      "Best rewards so far: 300.0\n",
      "Episode 7000 Epsilon 0.30030000000007706\n",
      "Episode 8000 Epsilon 0.20030000000008807\n",
      "Episode 9000 Epsilon 0.10030000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  4.0\n",
      "medium_reward  19.25\n",
      "0 [ 4 12 12  2]\n",
      "Best rewards so far: 26.0\n",
      "Best rewards so far: 29.0\n",
      "Best rewards so far: 30.0\n",
      "Best rewards so far: 32.0\n",
      "Best rewards so far: 36.0\n",
      "Best rewards so far: 63.0\n",
      "Best rewards so far: 75.0\n",
      "Episode 1000 Epsilon 0.900200000000011\n",
      "Best rewards so far: 97.0\n",
      "Episode 2000 Epsilon 0.800200000000022\n",
      "Episode 3000 Epsilon 0.700200000000033\n",
      "Episode 4000 Epsilon 0.600200000000044\n",
      "Episode 5000 Epsilon 0.500200000000055\n",
      "Episode 6000 Epsilon 0.40020000000006606\n",
      "Episode 7000 Epsilon 0.30020000000007707\n",
      "Episode 8000 Epsilon 0.20020000000008809\n",
      "Episode 9000 Epsilon 0.10020000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  0.0\n",
      "medium_reward  9.2\n",
      "1 [ 4 12 12  2]\n",
      "Best rewards so far: 28.0\n",
      "Best rewards so far: 31.0\n",
      "Best rewards so far: 33.0\n",
      "Best rewards so far: 34.0\n",
      "Best rewards so far: 58.0\n",
      "Best rewards so far: 59.0\n",
      "Best rewards so far: 62.0\n",
      "Best rewards so far: 73.0\n",
      "Best rewards so far: 74.0\n",
      "Best rewards so far: 107.0\n",
      "Episode 1000 Epsilon 0.900200000000011\n",
      "Episode 2000 Epsilon 0.800200000000022\n",
      "Episode 3000 Epsilon 0.700200000000033\n",
      "Episode 4000 Epsilon 0.600200000000044\n",
      "Best rewards so far: 124.0\n",
      "Episode 5000 Epsilon 0.500200000000055\n",
      "Best rewards so far: 126.0\n",
      "Best rewards so far: 170.0\n",
      "Episode 6000 Epsilon 0.40020000000006606\n",
      "Best rewards so far: 300.0\n",
      "Episode 7000 Epsilon 0.30020000000007707\n",
      "Episode 8000 Epsilon 0.20020000000008809\n",
      "Episode 9000 Epsilon 0.10020000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  100.0\n",
      "medium_reward  200.0\n",
      "success shape:  [ 4 12 12  2]\n",
      "1\n",
      "0 [ 4 12 12  2]\n",
      "Best rewards so far: 25.0\n",
      "Best rewards so far: 41.0\n",
      "Best rewards so far: 44.0\n",
      "Best rewards so far: 51.0\n",
      "Best rewards so far: 52.0\n",
      "Best rewards so far: 53.0\n",
      "Best rewards so far: 58.0\n",
      "Best rewards so far: 69.0\n",
      "Best rewards so far: 93.0\n",
      "Best rewards so far: 98.0\n",
      "Episode 1000 Epsilon 0.900300000000011\n",
      "Best rewards so far: 104.0\n",
      "Best rewards so far: 130.0\n",
      "Episode 2000 Epsilon 0.800300000000022\n",
      "Episode 3000 Epsilon 0.700300000000033\n",
      "Episode 4000 Epsilon 0.600300000000044\n",
      "Episode 5000 Epsilon 0.500300000000055\n",
      "Episode 6000 Epsilon 0.40030000000006605\n",
      "Episode 7000 Epsilon 0.30030000000007706\n",
      "Episode 8000 Epsilon 0.20030000000008807\n",
      "Episode 9000 Epsilon 0.10030000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  0.0\n",
      "medium_reward  9.29\n",
      "0 [ 4 12 12  2]\n",
      "Best rewards so far: 29.0\n",
      "Best rewards so far: 32.0\n",
      "Best rewards so far: 38.0\n",
      "Best rewards so far: 61.0\n",
      "Best rewards so far: 76.0\n",
      "Best rewards so far: 86.0\n",
      "Best rewards so far: 99.0\n",
      "Episode 1000 Epsilon 0.900200000000011\n",
      "Episode 2000 Epsilon 0.800200000000022\n",
      "Episode 3000 Epsilon 0.700200000000033\n",
      "Best rewards so far: 105.0\n",
      "Episode 4000 Epsilon 0.600200000000044\n",
      "Episode 5000 Epsilon 0.500200000000055\n",
      "Episode 6000 Epsilon 0.40020000000006606\n",
      "Episode 7000 Epsilon 0.30020000000007707\n",
      "Episode 8000 Epsilon 0.20020000000008809\n",
      "Episode 9000 Epsilon 0.10020000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  0.0\n",
      "medium_reward  9.88\n",
      "1 [ 4 12 12  2]\n",
      "Best rewards so far: 15.0\n",
      "Best rewards so far: 36.0\n",
      "Best rewards so far: 46.0\n",
      "Best rewards so far: 62.0\n",
      "Best rewards so far: 87.0\n",
      "Best rewards so far: 109.0\n",
      "Episode 1000 Epsilon 0.900200000000011\n",
      "Episode 2000 Epsilon 0.800200000000022\n",
      "Episode 3000 Epsilon 0.700200000000033\n",
      "Episode 4000 Epsilon 0.600200000000044\n",
      "Episode 5000 Epsilon 0.500200000000055\n",
      "Episode 6000 Epsilon 0.40020000000006606\n",
      "Episode 7000 Epsilon 0.30020000000007707\n",
      "Episode 8000 Epsilon 0.20020000000008809\n",
      "Episode 9000 Epsilon 0.10020000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  0.0\n",
      "medium_reward  9.43\n",
      "2 [ 4 12 12  2]\n",
      "Best rewards so far: 34.0\n",
      "Best rewards so far: 77.0\n",
      "Best rewards so far: 78.0\n",
      "Best rewards so far: 113.0\n",
      "Best rewards so far: 118.0\n",
      "Episode 1000 Epsilon 0.900100000000011\n",
      "Episode 2000 Epsilon 0.800100000000022\n",
      "Episode 3000 Epsilon 0.700100000000033\n",
      "Episode 4000 Epsilon 0.600100000000044\n",
      "Episode 5000 Epsilon 0.5001000000000551\n",
      "Best rewards so far: 161.0\n",
      "Episode 6000 Epsilon 0.40010000000006607\n",
      "Episode 7000 Epsilon 0.3001000000000771\n",
      "Best rewards so far: 300.0\n",
      "Episode 8000 Epsilon 0.2001000000000881\n",
      "Episode 9000 Epsilon 0.10010000000009565\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  100.0\n",
      "medium_reward  200.0\n",
      "success shape:  [ 4 12 12  2]\n",
      "2\n",
      "0 [ 4 12 12  2]\n",
      "Best rewards so far: 18.0\n",
      "Best rewards so far: 21.0\n",
      "Best rewards so far: 24.0\n",
      "Best rewards so far: 68.0\n",
      "Best rewards so far: 81.0\n",
      "Best rewards so far: 92.0\n",
      "Episode 1000 Epsilon 0.900300000000011\n",
      "Episode 2000 Epsilon 0.800300000000022\n",
      "Episode 3000 Epsilon 0.700300000000033\n",
      "Best rewards so far: 141.0\n",
      "Best rewards so far: 284.0\n",
      "Episode 4000 Epsilon 0.600300000000044\n",
      "Episode 5000 Epsilon 0.500300000000055\n",
      "Best rewards so far: 300.0\n",
      "Episode 6000 Epsilon 0.40030000000006605\n",
      "Episode 7000 Epsilon 0.30030000000007706\n",
      "Episode 8000 Epsilon 0.20030000000008807\n",
      "Episode 9000 Epsilon 0.10030000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  61.0\n",
      "medium_reward  127.05\n",
      "0 [ 4 12 12  2]\n",
      "Best rewards so far: 13.0\n",
      "Best rewards so far: 63.0\n",
      "Best rewards so far: 68.0\n",
      "Best rewards so far: 76.0\n",
      "Best rewards so far: 98.0\n",
      "Episode 1000 Epsilon 0.900100000000011\n",
      "Episode 2000 Epsilon 0.800100000000022\n",
      "Best rewards so far: 106.0\n",
      "Episode 3000 Epsilon 0.700100000000033\n",
      "Episode 4000 Epsilon 0.600100000000044\n",
      "Episode 5000 Epsilon 0.5001000000000551\n",
      "Episode 6000 Epsilon 0.40010000000006607\n",
      "Episode 7000 Epsilon 0.3001000000000771\n",
      "Episode 8000 Epsilon 0.2001000000000881\n",
      "Episode 9000 Epsilon 0.10010000000009565\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  0.0\n",
      "medium_reward  42.67\n",
      "1 [ 4 12 12  2]\n",
      "Best rewards so far: 8.0\n",
      "Best rewards so far: 35.0\n",
      "Best rewards so far: 55.0\n",
      "Best rewards so far: 58.0\n",
      "Best rewards so far: 63.0\n",
      "Best rewards so far: 74.0\n",
      "Best rewards so far: 75.0\n",
      "Best rewards so far: 106.0\n",
      "Episode 1000 Epsilon 0.900300000000011\n",
      "Episode 2000 Epsilon 0.800300000000022\n",
      "Episode 3000 Epsilon 0.700300000000033\n",
      "Best rewards so far: 119.0\n",
      "Best rewards so far: 126.0\n",
      "Episode 4000 Epsilon 0.600300000000044\n",
      "Best rewards so far: 172.0\n",
      "Episode 5000 Epsilon 0.500300000000055\n",
      "Episode 6000 Epsilon 0.40030000000006605\n",
      "Episode 7000 Epsilon 0.30030000000007706\n",
      "Best rewards so far: 178.0\n",
      "Best rewards so far: 300.0\n",
      "Episode 8000 Epsilon 0.20030000000008807\n",
      "Episode 9000 Epsilon 0.10030000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  74.0\n",
      "medium_reward  150.71\n",
      "1 [ 4 12 12  2]\n",
      "Best rewards so far: 27.0\n",
      "Best rewards so far: 77.0\n",
      "Best rewards so far: 95.0\n",
      "Episode 1000 Epsilon 0.900300000000011\n",
      "Episode 2000 Epsilon 0.800300000000022\n",
      "Episode 3000 Epsilon 0.700300000000033\n",
      "Episode 4000 Epsilon 0.600300000000044\n",
      "Episode 5000 Epsilon 0.500300000000055\n",
      "Episode 6000 Epsilon 0.40030000000006605\n",
      "Best rewards so far: 103.0\n",
      "Episode 7000 Epsilon 0.30030000000007706\n",
      "Episode 8000 Epsilon 0.20030000000008807\n",
      "Episode 9000 Epsilon 0.10030000000009566\n",
      "Best rewards so far: 300.0\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  89.0\n",
      "medium_reward  181.44\n",
      "1 [ 4 12 12  2]\n",
      "Best rewards so far: 13.0\n",
      "Best rewards so far: 23.0\n",
      "Best rewards so far: 26.0\n",
      "Best rewards so far: 27.0\n",
      "Best rewards so far: 30.0\n",
      "Best rewards so far: 53.0\n",
      "Best rewards so far: 73.0\n",
      "Best rewards so far: 102.0\n",
      "Episode 1000 Epsilon 0.900300000000011\n",
      "Best rewards so far: 117.0\n",
      "Episode 2000 Epsilon 0.800300000000022\n",
      "Episode 3000 Epsilon 0.700300000000033\n",
      "Episode 4000 Epsilon 0.600300000000044\n",
      "Episode 5000 Epsilon 0.500300000000055\n",
      "Episode 6000 Epsilon 0.40030000000006605\n",
      "Episode 7000 Epsilon 0.30030000000007706\n",
      "Best rewards so far: 119.0\n",
      "Episode 8000 Epsilon 0.20030000000008807\n",
      "Episode 9000 Epsilon 0.10030000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  0.0\n",
      "medium_reward  26.51\n",
      "2 [ 4 12 12  2]\n",
      "Best rewards so far: 21.0\n",
      "Best rewards so far: 31.0\n",
      "Best rewards so far: 57.0\n",
      "Best rewards so far: 78.0\n",
      "Best rewards so far: 95.0\n",
      "Episode 1000 Epsilon 0.900300000000011\n",
      "Best rewards so far: 116.0\n",
      "Episode 2000 Epsilon 0.800300000000022\n",
      "Episode 3000 Epsilon 0.700300000000033\n",
      "Episode 4000 Epsilon 0.600300000000044\n",
      "Episode 5000 Epsilon 0.500300000000055\n",
      "Episode 6000 Epsilon 0.40030000000006605\n",
      "Episode 7000 Epsilon 0.30030000000007706\n",
      "Episode 8000 Epsilon 0.20030000000008807\n",
      "Episode 9000 Epsilon 0.10030000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  0.0\n",
      "medium_reward  9.27\n",
      "0 [ 4 16 16  2]\n",
      "Best rewards so far: 21.0\n",
      "Best rewards so far: 29.0\n",
      "Best rewards so far: 45.0\n",
      "Best rewards so far: 47.0\n",
      "Best rewards so far: 49.0\n",
      "Best rewards so far: 65.0\n",
      "Best rewards so far: 83.0\n",
      "Best rewards so far: 89.0\n",
      "Episode 1000 Epsilon 0.900300000000011\n",
      "Episode 2000 Epsilon 0.800300000000022\n",
      "Episode 3000 Epsilon 0.700300000000033\n",
      "Episode 4000 Epsilon 0.600300000000044\n",
      "Episode 5000 Epsilon 0.500300000000055\n",
      "Best rewards so far: 96.0\n",
      "Episode 6000 Epsilon 0.40030000000006605\n",
      "Episode 7000 Epsilon 0.30030000000007706\n",
      "Best rewards so far: 165.0\n",
      "Best rewards so far: 300.0\n",
      "Episode 8000 Epsilon 0.20030000000008807\n",
      "Episode 9000 Epsilon 0.10030000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  100.0\n",
      "medium_reward  200.0\n",
      "success shape:  [ 4 16 16  2]\n",
      "3\n",
      "0 [ 4 12 12  2]\n",
      "Best rewards so far: 13.0\n",
      "Best rewards so far: 16.0\n",
      "Best rewards so far: 20.0\n",
      "Best rewards so far: 30.0\n",
      "Best rewards so far: 70.0\n",
      "Best rewards so far: 77.0\n",
      "Best rewards so far: 111.0\n",
      "Best rewards so far: 112.0\n",
      "Episode 1000 Epsilon 0.900300000000011\n",
      "Episode 2000 Epsilon 0.800300000000022\n",
      "Episode 3000 Epsilon 0.700300000000033\n",
      "Episode 4000 Epsilon 0.600300000000044\n",
      "Episode 5000 Epsilon 0.500300000000055\n",
      "Best rewards so far: 128.0\n",
      "Episode 6000 Epsilon 0.40030000000006605\n",
      "Episode 7000 Epsilon 0.30030000000007706\n",
      "Episode 8000 Epsilon 0.20030000000008807\n",
      "Episode 9000 Epsilon 0.10030000000009566\n",
      "Best rewards so far: 300.0\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  74.0\n",
      "medium_reward  151.87\n",
      "0 [ 4 12 12  2]\n",
      "Best rewards so far: 9.0\n",
      "Best rewards so far: 16.0\n",
      "Best rewards so far: 24.0\n",
      "Best rewards so far: 30.0\n",
      "Best rewards so far: 54.0\n",
      "Best rewards so far: 68.0\n",
      "Best rewards so far: 75.0\n",
      "Best rewards so far: 84.0\n",
      "Episode 1000 Epsilon 0.900400000000011\n",
      "Best rewards so far: 87.0\n",
      "Episode 2000 Epsilon 0.800400000000022\n",
      "Episode 3000 Epsilon 0.700400000000033\n",
      "Episode 4000 Epsilon 0.600400000000044\n",
      "Episode 5000 Epsilon 0.500400000000055\n",
      "Best rewards so far: 149.0\n",
      "Best rewards so far: 227.0\n",
      "Episode 6000 Epsilon 0.40040000000006604\n",
      "Episode 7000 Epsilon 0.30040000000007705\n",
      "Best rewards so far: 300.0\n",
      "Episode 8000 Epsilon 0.20040000000008806\n",
      "Episode 9000 Epsilon 0.10040000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  5.0\n",
      "medium_reward  21.5\n",
      "1 [ 4 12 12  2]\n",
      "Best rewards so far: 18.0\n",
      "Best rewards so far: 22.0\n",
      "Best rewards so far: 31.0\n",
      "Best rewards so far: 33.0\n",
      "Best rewards so far: 36.0\n",
      "Best rewards so far: 50.0\n",
      "Best rewards so far: 62.0\n",
      "Best rewards so far: 74.0\n",
      "Best rewards so far: 84.0\n",
      "Episode 1000 Epsilon 0.900300000000011\n",
      "Best rewards so far: 98.0\n",
      "Episode 2000 Epsilon 0.800300000000022\n",
      "Best rewards so far: 101.0\n",
      "Episode 3000 Epsilon 0.700300000000033\n",
      "Best rewards so far: 113.0\n",
      "Episode 4000 Epsilon 0.600300000000044\n",
      "Best rewards so far: 159.0\n",
      "Episode 5000 Epsilon 0.500300000000055\n",
      "Best rewards so far: 280.0\n",
      "Episode 6000 Epsilon 0.40030000000006605\n",
      "Best rewards so far: 300.0\n",
      "Episode 7000 Epsilon 0.30030000000007706\n",
      "Episode 8000 Epsilon 0.20030000000008807\n",
      "Episode 9000 Epsilon 0.10030000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  42.0\n",
      "medium_reward  142.9\n",
      "2 [ 4 12 12  2]\n",
      "Best rewards so far: 21.0\n",
      "Best rewards so far: 28.0\n",
      "Best rewards so far: 34.0\n",
      "Best rewards so far: 39.0\n",
      "Best rewards so far: 46.0\n",
      "Best rewards so far: 70.0\n",
      "Best rewards so far: 72.0\n",
      "Best rewards so far: 77.0\n",
      "Episode 1000 Epsilon 0.900300000000011\n",
      "Best rewards so far: 89.0\n",
      "Episode 2000 Epsilon 0.800300000000022\n",
      "Episode 3000 Epsilon 0.700300000000033\n",
      "Episode 4000 Epsilon 0.600300000000044\n",
      "Episode 5000 Epsilon 0.500300000000055\n",
      "Episode 6000 Epsilon 0.40030000000006605\n",
      "Episode 7000 Epsilon 0.30030000000007706\n",
      "Episode 8000 Epsilon 0.20030000000008807\n",
      "Episode 9000 Epsilon 0.10030000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  0.0\n",
      "medium_reward  9.25\n",
      "0 [ 4 16 16  2]\n",
      "Best rewards so far: 45.0\n",
      "Best rewards so far: 73.0\n",
      "Best rewards so far: 80.0\n",
      "Best rewards so far: 82.0\n",
      "Best rewards so far: 99.0\n",
      "Episode 1000 Epsilon 0.900200000000011\n",
      "Episode 2000 Epsilon 0.800200000000022\n",
      "Episode 3000 Epsilon 0.700200000000033\n",
      "Episode 4000 Epsilon 0.600200000000044\n",
      "Episode 5000 Epsilon 0.500200000000055\n",
      "Episode 6000 Epsilon 0.40020000000006606\n",
      "Best rewards so far: 102.0\n",
      "Episode 7000 Epsilon 0.30020000000007707\n",
      "Episode 8000 Epsilon 0.20020000000008809\n",
      "Episode 9000 Epsilon 0.10020000000009566\n",
      "Best rewards so far: 300.0\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  74.0\n",
      "medium_reward  151.52\n",
      "0 [ 4 16 16  2]\n",
      "Best rewards so far: 16.0\n",
      "Best rewards so far: 24.0\n",
      "Best rewards so far: 25.0\n",
      "Best rewards so far: 26.0\n",
      "Best rewards so far: 30.0\n",
      "Best rewards so far: 70.0\n",
      "Best rewards so far: 86.0\n",
      "Best rewards so far: 110.0\n",
      "Episode 1000 Epsilon 0.900400000000011\n",
      "Episode 2000 Epsilon 0.800400000000022\n",
      "Episode 3000 Epsilon 0.700400000000033\n",
      "Episode 4000 Epsilon 0.600400000000044\n",
      "Episode 5000 Epsilon 0.500400000000055\n",
      "Episode 6000 Epsilon 0.40040000000006604\n",
      "Episode 7000 Epsilon 0.30040000000007705\n",
      "Best rewards so far: 142.0\n",
      "Episode 8000 Epsilon 0.20040000000008806\n",
      "Episode 9000 Epsilon 0.10040000000009566\n",
      "Best rewards so far: 300.0\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  100.0\n",
      "medium_reward  200.0\n",
      "success shape:  [ 4 16 16  2]\n",
      "4\n",
      "0 [ 4 12 12  2]\n",
      "Best rewards so far: 10.0\n",
      "Best rewards so far: 30.0\n",
      "Best rewards so far: 51.0\n",
      "Best rewards so far: 54.0\n",
      "Best rewards so far: 70.0\n",
      "Best rewards so far: 78.0\n",
      "Best rewards so far: 80.0\n",
      "Best rewards so far: 93.0\n",
      "Episode 1000 Epsilon 0.900300000000011\n",
      "Best rewards so far: 126.0\n",
      "Episode 2000 Epsilon 0.800300000000022\n",
      "Episode 3000 Epsilon 0.700300000000033\n",
      "Episode 4000 Epsilon 0.600300000000044\n",
      "Episode 5000 Epsilon 0.500300000000055\n",
      "Episode 6000 Epsilon 0.40030000000006605\n",
      "Episode 7000 Epsilon 0.30030000000007706\n",
      "Episode 8000 Epsilon 0.20030000000008807\n",
      "Episode 9000 Epsilon 0.10030000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  0.0\n",
      "medium_reward  9.26\n",
      "0 [ 4 12 12  2]\n",
      "Best rewards so far: 26.0\n",
      "Best rewards so far: 34.0\n",
      "Best rewards so far: 48.0\n",
      "Best rewards so far: 72.0\n",
      "Best rewards so far: 115.0\n",
      "Episode 1000 Epsilon 0.900200000000011\n",
      "Episode 2000 Epsilon 0.800200000000022\n",
      "Episode 3000 Epsilon 0.700200000000033\n",
      "Episode 4000 Epsilon 0.600200000000044\n",
      "Episode 5000 Epsilon 0.500200000000055\n",
      "Episode 6000 Epsilon 0.40020000000006606\n",
      "Episode 7000 Epsilon 0.30020000000007707\n",
      "Episode 8000 Epsilon 0.20020000000008809\n",
      "Episode 9000 Epsilon 0.10020000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  0.0\n",
      "medium_reward  9.31\n",
      "1 [ 4 12 12  2]\n",
      "Best rewards so far: 33.0\n",
      "Best rewards so far: 38.0\n",
      "Best rewards so far: 46.0\n",
      "Best rewards so far: 60.0\n",
      "Best rewards so far: 65.0\n",
      "Best rewards so far: 105.0\n",
      "Episode 1000 Epsilon 0.900200000000011\n",
      "Episode 2000 Epsilon 0.800200000000022\n",
      "Episode 3000 Epsilon 0.700200000000033\n",
      "Episode 4000 Epsilon 0.600200000000044\n",
      "Episode 5000 Epsilon 0.500200000000055\n",
      "Best rewards so far: 111.0\n",
      "Best rewards so far: 120.0\n",
      "Best rewards so far: 132.0\n",
      "Best rewards so far: 135.0\n",
      "Episode 6000 Epsilon 0.40020000000006606\n",
      "Best rewards so far: 220.0\n",
      "Best rewards so far: 272.0\n",
      "Best rewards so far: 295.0\n",
      "Best rewards so far: 300.0\n",
      "Episode 7000 Epsilon 0.30020000000007707\n",
      "Episode 8000 Epsilon 0.20020000000008809\n",
      "Episode 9000 Epsilon 0.10020000000009566\n",
      "Episode 10000 Epsilon 0.01\n",
      "test_res  100.0\n",
      "medium_reward  200.0\n",
      "success shape:  [ 4 12 12  2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import import_ipynb\n",
    "from dqn_5 import DQN\n",
    "from dqn_5 import DQN_search\n",
    "\n",
    "game_name = \"MountainCar-v0\"\n",
    "env = gym.make(game_name)\n",
    "in_states = env.observation_space.shape[0]\n",
    "out_actions = env.action_space.n\n",
    "\n",
    "env.close()\n",
    "\n",
    "N_TESTS = 5\n",
    "s_res_cnt = 0\n",
    "for i in range(N_TESTS):\n",
    "    print(i)\n",
    "    search = DQN_search(dqn_model = DQN(game_name = game_name, mini_batch_size = 64, num_divisions = 50))\n",
    "    atypes = ['', 'ReLU', 'ReLU', 'Linear']\n",
    "    search.set_a_type_array(atypes)\n",
    "    search.set_lr(0.001)\n",
    "    start_net_shape = np.array([in_states, 2, 2, out_actions])\n",
    "    shape_steps = np.array([[0, 1, 0, 0], [0, 0, 1, 0]])\n",
    "    final_shape = np.array([in_states, 4, 4, out_actions])\n",
    "    n_models = 3\n",
    "    TSR = 95\n",
    "    test_res, shape, good_policy = search.search(n_models, TSR, epochs = 2000, \n",
    "                                                 start_shape = np.array(start_net_shape), \n",
    "                                                 shape_steps = shape_steps,\n",
    "                                                 final_shape = final_shape,\n",
    "                                                 adaptive_n_models = False,\n",
    "                                                 min_best_result = -10\n",
    "                                                )\n",
    "    if (test_res!= False):\n",
    "        s_res_cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89750986-5296-48d8-b815-ecfa0bc6c48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(100.0*s_res_cnt/N_TESTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba722fe3-20dd-4926-9fa6-119b33f410bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(out_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bd793-821e-4e92-bf30-a0bc80e2267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (test_res!= False):\n",
    "    model_ = DQN(game_name = 'MountainCar-v0', mini_batch_size = 64, num_divisions = 50)\n",
    "    res = model_.test(good_policy, 10, render = True)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a83b43-8c50-4380-aac4-9b8e8a693674",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065856ab-2936-47aa-abfd-7ac17629eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_space = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a8f9f7-1096-4712-9611-84514e46f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_space[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6dba9b-df9f-42bd-bbb2-1e2b3e14d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
