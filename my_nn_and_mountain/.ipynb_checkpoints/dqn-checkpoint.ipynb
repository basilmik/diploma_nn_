{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "K5feZBXDqSyO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K5feZBXDqSyO",
    "outputId": "f8fa2bd4-7df7-40c6-97a6-3a71739035a2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from gymnasium) (1.26.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from gymnasium) (4.8.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium[classic-control] in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from gymnasium[classic-control]) (1.26.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium[classic-control]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from gymnasium[classic-control]) (4.8.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium[classic-control]) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium[classic-control]) (7.1.0)\n",
      "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium[classic-control]) (2.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium[classic-control]) (3.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium\n",
    "!pip install gymnasium[classic-control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290e9d45-e28b-4603-9058-3260849a1668",
   "metadata": {
    "id": "290e9d45-e28b-4603-9058-3260849a1668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from plastic_nn.ipynb\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import import_ipynb\n",
    "from plastic_nn import plastic_nn\n",
    "from plastic_nn import input_layer\n",
    "from plastic_nn import layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cea6a06-3557-4e61-a769-420d9de43ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define memory for Experience Replay\n",
    "class ReplayMemory():\n",
    "    def __init__(self, maxlen):\n",
    "        self.memory = deque([], maxlen=maxlen)\n",
    "\n",
    "    def append(self, transition):\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        return random.sample(self.memory, sample_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MountainCarDQL():\n",
    "    # Hyperparameters (adjustable)\n",
    "    \n",
    "    discount_factor_g = 0.9         # discount rate (gamma)\n",
    "    network_sync_rate = 50000          # number of steps the agent takes before syncing the policy and target network\n",
    "    replay_memory_size = 100000       # size of replay memory\n",
    "    mini_batch_size = 32            # size of the training data set sampled from the replay memory\n",
    "\n",
    "    num_divisions = 20\n",
    "\n",
    "    \n",
    "    def plot_progress(self, rewards_per_episode, epsilon_history):\n",
    "        plt.figure(1)\n",
    "        plt.subplot(121) \n",
    "        plt.plot(rewards_per_episode)\n",
    "        plt.subplot(122) # plot on a 1 row x 2 col grid, at cell 2\n",
    "        plt.plot(epsilon_history)\n",
    "        plt.savefig('mountaincar_dql.png')\n",
    "\n",
    "    \n",
    "\n",
    "    def train(self, policy_dqn, target_dqn, episodes, render=False):\n",
    "        # Create FrozenLake instance\n",
    "        env = gym.make('MountainCar-v0', render_mode='human' if render else None)\n",
    "        num_states = env.observation_space.shape[0] # expecting 2: position & velocity\n",
    "        num_actions = env.action_space.n\n",
    "\n",
    "        # Divide position and velocity into segments\n",
    "        self.pos_space = np.linspace(env.observation_space.low[0], env.observation_space.high[0], self.num_divisions)    # Between -1.2 and 0.6\n",
    "        self.vel_space = np.linspace(env.observation_space.low[1], env.observation_space.high[1], self.num_divisions)    # Between -0.07 and 0.07\n",
    "\n",
    "        epsilon = 1 # 1 = 100% random actions\n",
    "        memory = ReplayMemory(self.replay_memory_size)\n",
    "\n",
    "        rewards_per_episode = []\n",
    "        epsilon_history = []\n",
    "\n",
    "        # Track number of steps taken. Used for syncing policy => target network.\n",
    "        step_count = 0\n",
    "        goal_reached = False\n",
    "        best_rewards = -200\n",
    "\n",
    "        for i in range(episodes):\n",
    "            state = env.reset()[0]  # Initialize to state 0\n",
    "            terminated = False      # True when agent falls in hole or reached goal\n",
    "            rewards = 0\n",
    "\n",
    "            # Agent navigates map until it falls into hole/reaches goal (terminated), or has taken 200 actions (truncated).\n",
    "            while(not terminated and rewards>-1000):\n",
    "                if random.random() < epsilon:\n",
    "                    action = env.action_space.sample() # actions: 0=left,1=idle,2=right\n",
    "                else:\n",
    "                    res = policy_dqn.forward(self.state_to_dqn_input(state))\n",
    "                    #print(res)\n",
    "                    action = res.argmax().item()\n",
    "\n",
    "                new_state,reward,terminated,truncated,_ = env.step(action)\n",
    "                rewards += reward\n",
    "                memory.append((state, action, new_state, reward, terminated))\n",
    "                state = new_state\n",
    "                step_count+=1\n",
    "\n",
    "\n",
    "            rewards_per_episode.append(rewards)\n",
    "            epsilon_history.append(epsilon)\n",
    "            \n",
    "            if(terminated):\n",
    "                goal_reached = True\n",
    "\n",
    "            # Graph training progress\n",
    "            if(i!=0 and i%1000==0):\n",
    "                print(f'Episode {i} Epsilon {epsilon}')\n",
    "\n",
    "                self.plot_progress(rewards_per_episode, epsilon_history)\n",
    "\n",
    "            if rewards>best_rewards:\n",
    "                best_rewards = rewards\n",
    "                print(f'Best rewards so far: {best_rewards}')\n",
    "                # Save policy\n",
    "                #torch.save(policy_dqn.state_dict(), f\"mountaincar_dql_{i}.pt\")\n",
    "\n",
    "            # Check if enough experience has been collected\n",
    "            if len(memory)>self.mini_batch_size and goal_reached:\n",
    "                #print(f'Episode {i} Epsilon {epsilon} rewards {rewards}') # print(rewards)\n",
    "                mini_batch = memory.sample(self.mini_batch_size) #len(memory))#\n",
    "                self.optimize(mini_batch, policy_dqn, target_dqn)\n",
    "\n",
    "                # Decay epsilon\n",
    "                epsilon = max(epsilon*0.9999, 0.05)#epsilon = max(epsilon - 1/episodes, 0)\n",
    "                epsilon_history.append(epsilon)\n",
    "\n",
    "                # Copy policy network to target network after a certain number of steps\n",
    "                if step_count > self.network_sync_rate:\n",
    "                    # print(\"BEFORE COPY\")\n",
    "                    # policy_dqn.print_info()\n",
    "                    # target_dqn.print_info()\n",
    "                    \n",
    "                    target_dqn = policy_dqn.deep_copy()\n",
    "                    \n",
    "                    # print(\"AFTER COPY\")\n",
    "                    # policy_dqn.print_info()\n",
    "                    # target_dqn.print_info()\n",
    "                    \n",
    "                    step_count = 0\n",
    "\n",
    "        env.close()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def optimize(self, mini_batch, policy_dqn, target_dqn):\n",
    "\n",
    "        current_q_list = []\n",
    "        target_q_list = []\n",
    "        print('before! ')\n",
    "        self.test(policy_dqn, 1)\n",
    "        \n",
    "        for state, action, new_state, reward, terminated in mini_batch:\n",
    "\n",
    "            if terminated:\n",
    "                target = reward\n",
    "            else:\n",
    "                target = reward + self.discount_factor_g * target_dqn.forward(self.state_to_dqn_input(new_state)).max()\n",
    "\n",
    "\n",
    "            # Get the target set of Q values\n",
    "            target_q = target_dqn.forward_nu(self.state_to_dqn_input(state))\n",
    "            \n",
    "            # Get the current set of Q values\n",
    "            current_q = policy_dqn.forward(self.state_to_dqn_input(state))\n",
    "            current_q_list.append(current_q)\n",
    "            \n",
    "            # Adjust the specific action to the target that was just calculated\n",
    "            target_q[action] = target\n",
    "            target_q_list.append(target_q)\n",
    "\n",
    "    \n",
    "            #BACKPOP AND UPDATE\n",
    "            #err =  target_q - current_q\n",
    "            #policy_dqn.backprop_error(err)\n",
    "            print('backprop\\n')\n",
    "            policy_dqn.backprop(target_q)\n",
    "            policy_dqn.update_w()\n",
    "\n",
    "            print('\\nupdate! ')\n",
    "            self.test(policy_dqn, 1)\n",
    "        \n",
    "        # Compute loss for the whole minibatch ??\n",
    "    \n",
    "        #loss = self.loss_fn(torch.stack(current_q_list), torch.stack(target_q_list))\n",
    "\n",
    "        # Optimize the model\n",
    "        #self.optimizer.zero_grad()\n",
    "        #loss.backward()\n",
    "        #self.optimizer.step()\n",
    "\n",
    "\n",
    "    def state_to_dqn_input(self, state)->torch.Tensor:\n",
    "        state_p = np.digitize(state[0], self.pos_space)\n",
    "        state_v = np.digitize(state[1], self.vel_space)\n",
    "\n",
    "        return torch.FloatTensor([state_p, state_v])\n",
    "\n",
    "    # Run the environment with the learned policy\n",
    "    def test(self, policy_dqn, episodes):\n",
    "        # Create FrozenLake instance\n",
    "        env = gym.make('MountainCar-v0', render_mode='human')\n",
    "        num_states = env.observation_space.shape[0]\n",
    "        num_actions = env.action_space.n\n",
    "\n",
    "        self.pos_space = np.linspace(env.observation_space.low[0], env.observation_space.high[0], self.num_divisions)    # Between -1.2 and 0.6\n",
    "        self.vel_space = np.linspace(env.observation_space.low[1], env.observation_space.high[1], self.num_divisions)    # Between -0.07 and 0.07\n",
    "\n",
    "        # Load learned policy\n",
    "        #policy_dqn = DQN(in_states=num_states, h1_nodes=10, out_actions=num_actions)\n",
    "        #policy_dqn.load_state_dict(torch.load(model_filepath))\n",
    "        #policy_dqn.eval()    # switch model to evaluation mode\n",
    "        flag = False\n",
    "        for i in range(episodes):\n",
    "            state = env.reset()[0]  # Initialize to state 0\n",
    "            terminated = False      # True when agent falls in hole or reached goal\n",
    "            truncated = False       # True when agent takes more than 200 actions\n",
    "\n",
    "            # Agent navigates map until it falls into a hole (terminated), reaches goal (terminated), or has taken 200 actions (truncated).\n",
    "            while(not terminated and not truncated):\n",
    "                res = policy_dqn.forward(self.state_to_dqn_input(state))\n",
    "                if (not flag):\n",
    "                    print(res)\n",
    "                    flag = True\n",
    "                action = res.argmax().item()\n",
    "\n",
    "                # Execute action\n",
    "                state,reward,terminated,truncated,_ = env.step(action)\n",
    "                terminated = True\n",
    "\n",
    "        env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f045c962-6024-43b8-8527-1376ce918872",
   "metadata": {
    "id": "f045c962-6024-43b8-8527-1376ce918872",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added LAYERS succesfully\n"
     ]
    }
   ],
   "source": [
    "learning_rate_a = 0.01\n",
    "in_states = 2\n",
    "h1_nodes = 10\n",
    "out_actions = 3\n",
    "\n",
    "layers_net = [input_layer(in_states), \n",
    "layer(lr = learning_rate_a, prev_size = in_states, my_size=h1_nodes, activation_type=\"ReLU\"), \n",
    "layer(lr = learning_rate_a, prev_size = h1_nodes, my_size=out_actions, activation_type='Linear')] #, activation_type=\"ReLU\")]\n",
    "\n",
    "policy_dqn = plastic_nn()\n",
    "policy_dqn.append(layers_net)\n",
    "\n",
    "target_dqn = plastic_nn()\n",
    "target_dqn = policy_dqn.deep_copy()\n",
    "        \n",
    "# env = gym.make('MountainCar-v0') #, render_mode='human' if render else None)\n",
    "# state, _ = env.reset()\n",
    "\n",
    "# pos_space = np.linspace(env.observation_space.low[0], env.observation_space.high[0], 20)    # Between -1.2 and 0.6\n",
    "# vel_space = np.linspace(env.observation_space.low[1], env.observation_space.high[1], 20)    # Between -0.07 and 0.07\n",
    "# state_p = np.digitize(state[0], pos_space)\n",
    "# state_v = np.digitize(state[1], vel_space)\n",
    "# state=[state_p, state_v]\n",
    "\n",
    "# print(policy_dqn.forward(state))\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "219350b2-41b7-44de-b105-8ab7aefd85bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mountaincar = MountainCarDQL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c55590b-3de2-4e5e-a9dc-10c7b25b598d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 993
    },
    "id": "8c55590b-3de2-4e5e-a9dc-10c7b25b598d",
    "outputId": "5d51151e-415f-4612-c064-a8a6a337d5d1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update! \n",
      "[56.74662085 56.07694281 37.04867163]\n",
      "0\n",
      "s.delta  [-421.84388691    0.            0.        ]\n",
      "s.prev_layer_error  [-291.75748542 -297.41626434  -75.0130683  -241.48732814 -276.23902922\n",
      " -317.67009645 -366.09936754 -319.71147723 -188.54231447  -52.02385505]\n",
      "1\n",
      "s.delta  [-291.75748542 -297.41626434  -75.0130683  -241.48732814 -276.23902922\n",
      " -317.67009645 -366.09936754 -319.71147723 -188.54231447  -52.02385505]\n",
      "s.prev_layer_error  [-1432.18623088 -1391.29114909]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0. -0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [ 0.  0. -0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n",
      "[0. 0. 0.]\n",
      "0\n",
      "s.delta  [-0.  0.  0.]\n",
      "s.prev_layer_error  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1\n",
      "s.delta  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "s.prev_layer_error  [0. 0.]\n",
      "update! \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmountaincar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_dqn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dqn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 103\u001b[0m, in \u001b[0;36mMountainCarDQL.train\u001b[1;34m(self, policy_dqn, target_dqn, episodes, render)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(memory)\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmini_batch_size \u001b[38;5;129;01mand\u001b[39;00m goal_reached:\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m#print(f'Episode {i} Epsilon {epsilon} rewards {rewards}') # print(rewards)\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     mini_batch \u001b[38;5;241m=\u001b[39m memory\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmini_batch_size) \u001b[38;5;66;03m#len(memory))#\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_dqn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dqn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# Decay epsilon\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(epsilon\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.9999\u001b[39m, \u001b[38;5;241m0.05\u001b[39m)\u001b[38;5;66;03m#epsilon = max(epsilon - 1/episodes, 0)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 162\u001b[0m, in \u001b[0;36mMountainCarDQL.optimize\u001b[1;34m(self, mini_batch, policy_dqn, target_dqn)\u001b[0m\n\u001b[0;32m    159\u001b[0m policy_dqn\u001b[38;5;241m.\u001b[39mupdate_w()\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdate! \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_dqn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 196\u001b[0m, in \u001b[0;36mMountainCarDQL.test\u001b[1;34m(self, policy_dqn, episodes)\u001b[0m\n\u001b[0;32m    194\u001b[0m flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episodes):\n\u001b[1;32m--> 196\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Initialize to state 0\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m      \u001b[38;5;66;03m# True when agent falls in hole or reached goal\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m       \u001b[38;5;66;03m# True when agent takes more than 200 actions\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\wrappers\\time_limit.py:75\u001b[0m, in \u001b[0;36mTimeLimit.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with :param:`**kwargs` and sets the number of steps elapsed to zero.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    The reset environment\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:61\u001b[0m, in \u001b[0;36mOrderEnforcing.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\wrappers\\env_checker.py:57\u001b[0m, in \u001b[0;36mPassiveEnvChecker.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_reset:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_reset_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\utils\\passive_env_checker.py:186\u001b[0m, in \u001b[0;36menv_reset_passive_checker\u001b[1;34m(env, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdeprecation(\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# Checks the result of env.reset with kwargs\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m result \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    189\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\envs\\classic_control\\mountain_car.py:164\u001b[0m, in \u001b[0;36mMountainCarEnv.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnp_random\u001b[38;5;241m.\u001b[39muniform(low\u001b[38;5;241m=\u001b[39mlow, high\u001b[38;5;241m=\u001b[39mhigh), \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32), {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\envs\\classic_control\\mountain_car.py:266\u001b[0m, in \u001b[0;36mMountainCarEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    265\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mflip()\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mountaincar.train(policy_dqn, target_dqn, 4000, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71956c2f-0661-4b8c-bc5d-245dd9dfe786",
   "metadata": {
    "id": "71956c2f-0661-4b8c-bc5d-245dd9dfe786",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mountaincar.test(policy_dqn, 1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
