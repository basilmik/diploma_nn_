{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66fff9ae-68b5-445d-b9e7-e300cd3cb812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install import-ipynb\n",
    "# !pip install gymnasium\n",
    "# !pip install gymnasium[classic-control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a16b4c-b759-484d-ae13-9619ac3e0586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from plastic_nn.ipynb\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import random\n",
    "import copy\n",
    "import import_ipynb\n",
    "from plastic_nn import plastic_nn\n",
    "from plastic_nn import input_layer\n",
    "from plastic_nn import layer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e102abc-f92d-44b7-a627-9c14b276bf91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# random.seed(42)\n",
    "# num_of_inputs = 4\n",
    "# hidden1 = 6 \n",
    "# hidden2 = 6\n",
    "# out_n = 2\n",
    "\n",
    "# lr = 0.1\n",
    "\n",
    "\n",
    "# layers_net = [input_layer(num_of_inputs), \n",
    "#           layer(lr = lr, prev_size = num_of_inputs, my_size=hidden1, activation_type=\"ReLU\"), \n",
    "#           layer(lr = lr, prev_size = hidden1, my_size=hidden2, activation_type=\"ReLU\"), \n",
    "#           layer(lr = lr, prev_size = hidden2, my_size=out_n, activation_type='Linear')] #, activation_type=\"ReLU\")]\n",
    "\n",
    "# brain = plastic_nn()\n",
    "# brain.append(layers_net)\n",
    "\n",
    "class replay_memory:\n",
    "    def __init__(s, max_len):\n",
    "        s.memory = deque([], maxlen=max_len)\n",
    "\n",
    "    def append(s, val):\n",
    "        s.memory.append(val)\n",
    "        \n",
    "    def clear(s):\n",
    "        s.memory.clear()\n",
    "\n",
    "    def get_sample(s, sample_size):\n",
    "        return random.sample(s.memory, sample_size)\n",
    "\n",
    "    def __len__(s):\n",
    "        return len(s.memory)\n",
    "\n",
    "    #cur_state, action, next_state, reward, terminated\n",
    "    def print(s):\n",
    "        for m in s.memory:\n",
    "            print(\"state: \", cart_pole_state_to_human(m[0]))\n",
    "            print(\"action: \", cart_pole_action_to_human(m[1]))\n",
    "            print(\"next state: \", cart_pole_state_to_human(m[2]))\n",
    "            print(\"reward: \", m[3])\n",
    "            print(\"termninated?: \", m[4])\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0855527a-a9f5-4f5c-8576-83a563ebb6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added LAYERS succesfully\n",
      "32\n",
      "\n",
      "e:  0  explore_prob:  0  sum:  31  rand/total:  0.0 \n",
      "----------------------\n",
      "\n",
      "66\n",
      "\n",
      "e:  1  explore_prob:  0  sum:  33  rand/total:  0.0 \n",
      "----------------------\n",
      "\n",
      "74\n",
      "\n",
      "e:  2  explore_prob:  0  sum:  7  rand/total:  0.0 \n",
      "----------------------\n",
      "\n",
      "82\n",
      "\n",
      "e:  3  explore_prob:  0  sum:  7  rand/total:  0.0 \n",
      "----------------------\n",
      "\n",
      "90\n",
      "\n",
      "e:  4  explore_prob:  0  sum:  7  rand/total:  0.0 \n",
      "----------------------\n",
      "\n",
      "98\n",
      "\n",
      "e:  5  explore_prob:  0  sum:  7  rand/total:  0.0 \n",
      "----------------------\n",
      "\n",
      "106\n",
      "\n",
      "e:  6  explore_prob:  0  sum:  7  rand/total:  0.0 \n",
      "----------------------\n",
      "\n",
      "114\n",
      "\n",
      "e:  7  explore_prob:  0  sum:  7  rand/total:  0.0 \n",
      "----------------------\n",
      "\n",
      "122\n",
      "\n",
      "e:  8  explore_prob:  0  sum:  7  rand/total:  0.0 \n",
      "----------------------\n",
      "\n",
      "130\n",
      "\n",
      "e:  9  explore_prob:  0  sum:  7  rand/total:  0.0 \n",
      "----------------------\n",
      "\n",
      "138\n",
      "\n",
      "e:  10  explore_prob:  0  sum:  7  rand/total:  0.0 \n",
      "----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "num_of_inputs = 4\n",
    "hidden1 = 64 \n",
    "hidden2 = 42\n",
    "out_n = 2\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "layers_net = [input_layer(num_of_inputs), \n",
    "          layer(lr = lr, prev_size = num_of_inputs, my_size=hidden1, activation_type=\"ReLU\"), \n",
    "          layer(lr = lr, prev_size = hidden1, my_size=hidden2, activation_type=\"ReLU\"), \n",
    "          layer(lr = lr, prev_size = hidden2, my_size=out_n, activation_type='Linear')] #, activation_type=\"ReLU\")]\n",
    "\n",
    "brain = plastic_nn()\n",
    "brain.append(layers_net)\n",
    "brain.give_name('ALEX')\n",
    "\n",
    "def discrete_state(state):\n",
    "    step_size = np.array([0.25, 0.25, 0.01, 0.01])\n",
    "    ds = state/step_size + np.array([15,12,1,10])\n",
    "    return tuple(ds.astype(int))\n",
    "    #return state\n",
    "\n",
    "memory = replay_memory(max_len = 1000)\n",
    "\n",
    "\n",
    "def learn():\n",
    "    global brain\n",
    "\n",
    "\n",
    "    batch_size = min(len(memory), 32)\n",
    "    batch = memory.get_sample(batch_size)\n",
    "    \n",
    "    learning_brain = brain.deep_copy()\n",
    "    learning_brain.give_name('OLEG')\n",
    "\n",
    "    #print('JUST COPIED:')\n",
    "    #learning_brain.print_info()\n",
    "    #brain.print_info()    \n",
    "    \n",
    "    for prev_state, action, new_state, reward, done_s in batch:\n",
    "        #print(prev_state, action, now_state, reward, done_s)\n",
    "        \n",
    "        if (done_s):\n",
    "            new_q = reward\n",
    "        else:\n",
    "            expected_next_max_reward = brain.forward_nu(now_state).max()\n",
    "            new_q = reward + gamma*expected_next_max_reward       \n",
    "\n",
    "        current_res = brain.forward_nu(prev_state) # no input update\n",
    "        \n",
    "        target_res = learning_brain.forward(prev_state)\n",
    "        target_res[action] = new_q\n",
    "        #print('action: ', action)\n",
    "        #print('new val: ', new_q)\n",
    "        #print('target res: ', target_res)\n",
    "        #print('cur_res: ', current_res)\n",
    "        err = target_res - current_res\n",
    "        #print('error: ', err)\n",
    "        learning_brain.backprop_error(err)\n",
    "        learning_brain.update_w()\n",
    "        #print('check correction: ', learning_brain.forward_nu(prev_state))\n",
    "    \n",
    "        #print('AFTER LEARNING')\n",
    "        #learning_brain.print_info()\n",
    "        \n",
    "        #brain.print_info()\n",
    "    \n",
    "    brain = learning_brain.deep_copy()\n",
    "    brain.give_name('ALEX')\n",
    "    \n",
    "    #print('AFTER DEEP_COPY')\n",
    "    #learning_brain.print_info()\n",
    "    #brain.print_info()\n",
    "\n",
    "\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "epochs = 10\n",
    "env = gym.make('CartPole-v0') #, render_mode=\"human\")\n",
    "\n",
    "explore_disc_rate = 0.999\n",
    "explore_prob = 0\n",
    "gamma = 0.95\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for e in range(epochs+1):\n",
    "    truncated = False\n",
    "    terminated = False\n",
    "    \n",
    "    prev_state, info = env.reset(seed = seed_val) # seed = seed_val\n",
    "\n",
    "    \n",
    "    prev_reward = 0\n",
    "    total_sum = 0\n",
    "    rand_action_count = 0\n",
    "    while not truncated and not terminated:\n",
    "        #time.sleep(0.5)\n",
    "        #print('\\t',time_sum)\n",
    "        \n",
    "        if (random.random() < explore_prob): \n",
    "            rand_action_count +=1\n",
    "            action = env.action_space.sample() # explore      \n",
    "        else:\n",
    "\n",
    "            last_res = brain.forward(discrete_state(prev_state))\n",
    "            action = last_res.argmax().item()      \n",
    "\n",
    "        \n",
    "        \n",
    "        now_state, reward, terminated, done_s, info = env.step(action)\n",
    "        \n",
    "        if not done_s and not terminated:\n",
    "            total_sum += 1\n",
    "            \n",
    "        if done_s:\n",
    "            reward = total_sum + 20\n",
    "        elif terminated:\n",
    "            reward = -1#total_sum\n",
    "        else:\n",
    "            reward = 1#total_sum\n",
    "            \n",
    "        memory.append((prev_state, action, now_state, reward, done_s))\n",
    "        \n",
    "        \n",
    "        prev_state = now_state\n",
    "\n",
    "        if terminated or done_s:\n",
    "            print(len(memory))\n",
    "            if (len(memory) >= 32):\n",
    "                #print('BEFORE ---------')\n",
    "                #brain.print_info()\n",
    "                \n",
    "                learn()\n",
    "                \n",
    "                #print('AFTER ----------')\n",
    "                #brain.print_info()\n",
    "                if (explore_prob > 0.01):\n",
    "                    explore_prob *= explore_disc_rate\n",
    "\n",
    "    \n",
    "    if (e%1 == 0):\n",
    "        print('\\ne: ', e, ' explore_prob: ', explore_prob, \n",
    "              ' sum: ', total_sum, ' rand/total: ', rand_action_count/total_sum,'\\n----------------------\\n')        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "env.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87ee002-60bf-4f22-bd49-f69b4e0c4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b27767-b354-452f-985f-7c191f251647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
