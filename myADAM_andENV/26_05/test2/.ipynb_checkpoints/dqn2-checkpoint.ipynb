{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K5feZBXDqSyO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K5feZBXDqSyO",
    "outputId": "f8fa2bd4-7df7-40c6-97a6-3a71739035a2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install gymnasium\n",
    "!pip install gymnasium[classic-control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e9d45-e28b-4603-9058-3260849a1668",
   "metadata": {
    "id": "290e9d45-e28b-4603-9058-3260849a1668"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "import import_ipynb\n",
    "from TrulyPlastic_allOpt import plastic_nn\n",
    "from TrulyPlastic_allOpt import input_layer\n",
    "from TrulyPlastic_allOpt import layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea29ee5-b349-4619-8137-3d460e672f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea6a06-3557-4e61-a769-420d9de43ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define memory for Experience Replay\n",
    "class ReplayMemory():\n",
    "    def __init__(self, maxlen):\n",
    "        self.memory = deque([], maxlen=maxlen)\n",
    "\n",
    "    def append(self, transition):\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        return random.sample(self.memory, sample_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DQN():\n",
    "    # Hyperparameters (adjustable)\n",
    "    def __init__(s, ct, path = r'test', game_name = 'MountainCar-v0', discount_factor_g = 0.9, mini_batch_size = 64, \n",
    "                  num_divisions = 50, replay_memory_size = 100000, network_sync_rate = 50000):\n",
    "        s.ct = ct\n",
    "        \n",
    "        s.path = path\n",
    "        current_directory = os.getcwd()\n",
    "        final_directory = os.path.join(current_directory, s.path)\n",
    "        if not os.path.exists(final_directory):\n",
    "            os.makedirs(final_directory)\n",
    "    \n",
    "        s.game_name = game_name\n",
    "        s.discount_factor_g = discount_factor_g\n",
    "         \n",
    "        s.mini_batch_size = mini_batch_size \n",
    "        s.num_divisions = num_divisions\n",
    "\n",
    "        s.replay_memory_size =  replay_memory_size \n",
    "        s.network_sync_rate = network_sync_rate\n",
    "        \n",
    "    \n",
    "    def plot_progress(self, rewards_per_episode, epsilon_history):\n",
    "        \n",
    "        plt.figure(1)\n",
    "        plt.subplot(121) \n",
    "        plt.subplots_adjust(wspace=0.5, hspace=0.3)\n",
    "        \n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('reward')\n",
    "        plt.plot(rewards_per_episode)\n",
    "        plt.subplot(122) # plot on a 1 row x 2 col grid, at cell 2\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('epsilon')\n",
    "        plt.plot(epsilon_history)\n",
    "        plt.savefig(f'{self.path}/info_{self.ct}.png'.format(self.path, self.ct))\n",
    "\n",
    "    \n",
    "\n",
    "    def train(self, policy_dqn, target_dqn, episodes, render=False):\n",
    "        # Create FrozenLake instance\n",
    "        env = gym.make(self.game_name, render_mode='human' if render else None)\n",
    "        num_states = env.observation_space.shape[0] # expecting 2: position & velocity\n",
    "        num_actions = env.action_space.n\n",
    "\n",
    "        # Divide position and velocity into segments\n",
    "        self.pos_space = np.linspace(env.observation_space.low[0], env.observation_space.high[0], self.num_divisions)    # Between -1.2 and 0.6\n",
    "        self.vel_space = np.linspace(env.observation_space.low[1], env.observation_space.high[1], self.num_divisions)    # Between -0.07 and 0.07\n",
    "\n",
    "        epsilon = 1 # 1 = 100% random actions\n",
    "        memory = ReplayMemory(self.replay_memory_size)\n",
    "\n",
    "        rewards_per_episode = []\n",
    "        epsilon_history = []\n",
    "\n",
    "        # Track number of steps taken. Used for syncing policy => target network.\n",
    "        step_count = 0\n",
    "        goal_reached = False\n",
    "        best_rewards = -200\n",
    "\n",
    "        for i in range(episodes):\n",
    "            state = env.reset()[0]  # Initialize to state 0\n",
    "            terminated = False      # True when agent falls in hole or reached goal\n",
    "            truncated = False\n",
    "            rewards = 0\n",
    "\n",
    "            while(not terminated and rewards > -1000):\n",
    "                if random.random() < epsilon:\n",
    "                    action = env.action_space.sample() # actions: 0=left,1=idle,2=right\n",
    "                else:\n",
    "                    res = policy_dqn.forward(self.state_to_dqn_input(state))\n",
    "                    action = res.argmax().item()\n",
    "\n",
    "                new_state,reward,terminated,truncated,_ = env.step(action)\n",
    "                rewards += reward\n",
    "                memory.append((state, action, new_state, reward, terminated))\n",
    "                state = new_state\n",
    "                step_count+=1\n",
    "\n",
    "\n",
    "            rewards_per_episode.append(rewards)\n",
    "            \n",
    "            if(terminated):\n",
    "                goal_reached = True\n",
    "\n",
    "            # Graph training progress\n",
    "            if(i!=0 and i%1000==0):\n",
    "                print(f'Episode {i} Epsilon {epsilon}')\n",
    "                s.add_log_data(f'Episode {i} Epsilon {epsilon}')\n",
    "                \n",
    "                policy_dqn.save(f'{self.path}/mc_policy_{i}'.format(self.path, i))\n",
    "                self.plot_progress(rewards_per_episode, epsilon_history)\n",
    "\n",
    "            if rewards>best_rewards:\n",
    "                best_rewards = rewards\n",
    "                print(f'Best rewards so far: {best_rewards}')\n",
    "                s.add_log_data(f'Best rewards so far: {best_rewards}')\n",
    "                policy_dqn.save(f'{self.path}/mc_policy_{i}'.format(self.path, i))\n",
    "                \n",
    "\n",
    "            # Check if enough experience has been collected\n",
    "            if len(memory)>self.mini_batch_size and goal_reached:\n",
    "                \n",
    "                #print(f'OPTIMIZE Episode {i} Epsilon {epsilon} rewards {rewards}') # print(rewards)\n",
    "                \n",
    "                mini_batch = memory.sample(self.mini_batch_size)\n",
    "                self.optimize(mini_batch, policy_dqn, target_dqn)\n",
    "\n",
    "                # Decay epsilon\n",
    "                epsilon = epsilon = max(epsilon - 1/episodes, 0.01) # max(epsilon*0.99996, 0.05)#\n",
    "                epsilon_history.append(epsilon)\n",
    "\n",
    "                # Copy policy network to target network after a certain number of steps\n",
    "                if step_count > self.network_sync_rate:\n",
    "                    target_dqn = policy_dqn.deep_copy()\n",
    "                    step_count = 0\n",
    "                   \n",
    "                \n",
    "                \n",
    "        env.close()\n",
    "        policy_dqn.save(f'{self.ct}/mc_policy_last'.format(ct))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def optimize(self, mini_batch, policy_dqn, target_dqn):\n",
    "        target_q_list = []\n",
    "        input_list = []\n",
    "        \n",
    "        for state, action, new_state, reward, terminated in mini_batch:\n",
    "            if terminated:\n",
    "                target = reward\n",
    "            else:\n",
    "                target = reward + self.discount_factor_g * target_dqn.forward(self.state_to_dqn_input(new_state)).max()\n",
    "\n",
    "            # Get the target set of Q values\n",
    "            state_dsc = np.asarray(self.state_to_dqn_input(state))\n",
    "            input_list.append(state_dsc)\n",
    "            \n",
    "            target_q = target_dqn.forward(state_dsc)\n",
    "            \n",
    "            # Adjust the specific action to the target that was just calculated\n",
    "            target_q[action] = target            \n",
    "            target_q_list.append(target_q)\n",
    "\n",
    "        #BACKPOP AND UPDATE on minibatch\n",
    "        x = np.asarray(input_list)\n",
    "        x = x[:, :, 0]\n",
    "        x = x.T\n",
    "\n",
    "        y = np.asarray(target_q_list)\n",
    "        y = y[:, :, 0]\n",
    "        y = y.T\n",
    "\n",
    "        policy_dqn.learn_one(x, y)\n",
    "\n",
    "\n",
    "\n",
    "    def state_to_dqn_input(self, state):\n",
    "        state_p = np.digitize(state[0], self.pos_space)\n",
    "        state_v = np.digitize(state[1], self.vel_space)\n",
    "\n",
    "        return np.asarray([[state_p], [state_v]])\n",
    "\n",
    "        \n",
    "\n",
    "    def test(self, policy_dqn, episodes, render = False):\n",
    "        env = gym.make(self.game_name, render_mode='human' if render else None)\n",
    "        \n",
    "        num_states = env.observation_space.shape[0]\n",
    "        num_actions = env.action_space.n\n",
    "\n",
    "        self.pos_space = np.linspace(env.observation_space.low[0], env.observation_space.high[0], self.num_divisions)    # Between -1.2 and 0.6\n",
    "        self.vel_space = np.linspace(env.observation_space.low[1], env.observation_space.high[1], self.num_divisions)    # Between -0.07 and 0.07\n",
    "\n",
    "        done_count = 0\n",
    "        \n",
    "        for i in range(episodes):\n",
    "            state, info = env.reset()  # Initialize to state 0\n",
    "            done = False      # True when agent falls in hole or reached goal\n",
    "            truncated = False       # True when agent takes more than 200 actions\n",
    "\n",
    "            # Agent navigates map until it falls into a hole (terminated), reaches goal (terminated), or has taken 200 actions (truncated).\n",
    "            while(not done and not truncated):\n",
    "                state = self.state_to_dqn_input(state)\n",
    "                #print('state shape', state.shape)\n",
    "               \n",
    "                res = policy_dqn.forward(state)\n",
    "\n",
    "                action = res.argmax().item()\n",
    "                #print(res)\n",
    "                state, reward, done, truncated, _ = env.step(action)\n",
    "                if (done):\n",
    "                    done_count += 1\n",
    "\n",
    "        print(done_count/episodes)\n",
    "        env.close()\n",
    "\n",
    "    def save_info(s, ct, topology):\n",
    "        file_path = f'{s.path}/info.txt'.format(s.path)\n",
    "        f = open(file_path, \"a\")   \n",
    "       \n",
    "        f.write(\"{}\\n\".format(s.ct))\n",
    "        \n",
    "        f.write(\"{}\\n\".format(s.game_name))\n",
    "        f.write(\"{}\\n\".format(s.discount_factor_g))\n",
    "        f.write(\"{}\\n\".format(s.mini_batch_size))\n",
    "        f.write(\"{}\\n\".format(s.num_divisions))\n",
    "        f.write(\"{}\\n\".format(s.replay_memory_size))\n",
    "        f.write(\"{}\\n\".format(s.network_sync_rate))\n",
    "        f.write(\"{}\\n\".format(topology))\n",
    "                         \n",
    "        f.close()\n",
    "\n",
    "    def add_log_data(s, data)\n",
    "        file_path = f'{s.path}/info.txt'.format(s.path)\n",
    "        f = open(file_path, \"a\") \n",
    "        f.write(\"{}\\n\".format(data))\n",
    "                         \n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f045c962-6024-43b8-8527-1376ce918872",
   "metadata": {
    "id": "f045c962-6024-43b8-8527-1376ce918872",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate_a = 0.001\n",
    "in_states = 2\n",
    "h1_nodes = 100\n",
    "h2_nodes = 100\n",
    "out_actions = 3\n",
    "\n",
    "a_type1 = 'ReLU'\n",
    "a_type2 = 'Linear'\n",
    "\n",
    "layers_net = [input_layer(in_states), \n",
    "layer(lr = learning_rate_a, prev_size = in_states, my_size=h1_nodes, activation_type=a_type1), \n",
    "#layer(lr = learning_rate_a, prev_size = h1_nodes, my_size=h2_nodes, activation_type=\"ReLU\"), \n",
    "layer(lr = learning_rate_a, prev_size = h2_nodes, my_size=out_actions, activation_type=a_type2)]\n",
    "\n",
    "policy_dqn = plastic_nn(optimizer=\"Adam\")\n",
    "policy_dqn.append_layers(layers_net)\n",
    "\n",
    "target_dqn = plastic_nn()\n",
    "target_dqn = policy_dqn.deep_copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c8eaab-4e8c-497b-9cfc-0dd2cf1f9cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = datetime.datetime.now()\n",
    "ct = str(ct)\n",
    "ct = ct.replace(\":\", \"-\")\n",
    "ct = ct.replace(\" \", \"_\")\n",
    "ct = ct[:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219350b2-41b7-44de-b105-8ab7aefd85bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mountaincar = DQN(ct, path = ct, game_name = 'MountainCar-v0', discount_factor_g = 0.9, mini_batch_size = 64, \n",
    "                  num_divisions = 50, replay_memory_size = 100000, network_sync_rate = 50000)\n",
    "mountaincar.save_info(ct, f'lr: {learning_rate_a} \\nin:{in_states} \\nh:{h1_nodes} \\nout:{out_actions} \\na1:{a_type1} \\na2:{a_type2} \\n'.format(\n",
    "    learning_rate_a, in_states, h1_nodes, out_actions, a_type1, a_type2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55590b-3de2-4e5e-a9dc-10c7b25b598d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 993
    },
    "id": "8c55590b-3de2-4e5e-a9dc-10c7b25b598d",
    "outputId": "5d51151e-415f-4612-c064-a8a6a337d5d1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mountaincar.train(policy_dqn, target_dqn, 20000, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c628ab-e67d-4826-b24c-d7fbd73f8366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a07137-0867-4bfd-a11e-bc208a3cee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added LAYERS succesfully\n"
     ]
    }
   ],
   "source": [
    "#policy_dqn.load('2024-05-27_17-25-01/mc_policy_18143')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71956c2f-0661-4b8c-bc5d-245dd9dfe786",
   "metadata": {
    "id": "71956c2f-0661-4b8c-bc5d-245dd9dfe786",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "mountaincar.test(policy_dqn, 4, render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2baf01c5-f2fc-48c3-aee3-27e1ff536917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME:  noname  ( 3 )\n",
      "# 0\n",
      "IN LAYER\n",
      "size:  2\n",
      "\n",
      "# 1\n",
      "my size:  32\n",
      "prev size:  2\n",
      "w:  [[-2.72965090e-01  4.65795556e-03]\n",
      " [ 4.39312084e-02 -5.87615344e-02]\n",
      " [ 1.51004116e-02  1.53689642e-01]\n",
      " [-8.68260302e-02  1.55476522e-01]\n",
      " [-1.37891000e-01  3.75900522e-01]\n",
      " [-2.02415540e-01  2.07961092e-01]\n",
      " [-1.95920366e-01  2.72990630e-03]\n",
      " [-1.71192271e-01  4.17900883e-01]\n",
      " [-4.47059298e-01  3.61449817e-03]\n",
      " [ 1.70041461e-01 -1.06982520e-01]\n",
      " [ 1.10903454e-01  4.76861679e-02]\n",
      " [-4.77833700e-01  1.74715194e-03]\n",
      " [-2.72444800e-01  1.01057440e-02]\n",
      " [ 1.62759542e-01 -6.13162779e-02]\n",
      " [ 1.39703770e-01 -1.25945232e-01]\n",
      " [-6.17570436e-01  3.90188131e-01]\n",
      " [-7.52195119e-01  3.09538143e-02]\n",
      " [-7.78831518e-02 -7.25747210e-02]\n",
      " [-7.95239025e-02 -2.14568762e-02]\n",
      " [-1.26090495e-01  9.22705116e-02]\n",
      " [-5.15533079e-02  3.79980150e-01]\n",
      " [-4.39563394e-01  1.05257244e-02]\n",
      " [ 1.09041672e-01 -1.26023043e-01]\n",
      " [-1.67351589e-01  5.31793658e-03]\n",
      " [ 1.12915055e-01 -1.61599301e-01]\n",
      " [-4.60193648e-01 -2.96645496e-03]\n",
      " [ 2.99849061e-04 -7.77524869e-02]\n",
      " [-2.96851953e-01  3.62193764e-01]\n",
      " [-5.84744853e-01  3.64993781e-01]\n",
      " [-3.59678243e-01 -8.08273134e-03]\n",
      " [-3.59989100e-01 -5.31747161e-02]\n",
      " [-5.99881401e-03 -2.17799129e-02]] \n",
      "\n",
      "b:  [[-2.72965090e-01  4.65795556e-03]\n",
      " [ 4.39312084e-02 -5.87615344e-02]\n",
      " [ 1.51004116e-02  1.53689642e-01]\n",
      " [-8.68260302e-02  1.55476522e-01]\n",
      " [-1.37891000e-01  3.75900522e-01]\n",
      " [-2.02415540e-01  2.07961092e-01]\n",
      " [-1.95920366e-01  2.72990630e-03]\n",
      " [-1.71192271e-01  4.17900883e-01]\n",
      " [-4.47059298e-01  3.61449817e-03]\n",
      " [ 1.70041461e-01 -1.06982520e-01]\n",
      " [ 1.10903454e-01  4.76861679e-02]\n",
      " [-4.77833700e-01  1.74715194e-03]\n",
      " [-2.72444800e-01  1.01057440e-02]\n",
      " [ 1.62759542e-01 -6.13162779e-02]\n",
      " [ 1.39703770e-01 -1.25945232e-01]\n",
      " [-6.17570436e-01  3.90188131e-01]\n",
      " [-7.52195119e-01  3.09538143e-02]\n",
      " [-7.78831518e-02 -7.25747210e-02]\n",
      " [-7.95239025e-02 -2.14568762e-02]\n",
      " [-1.26090495e-01  9.22705116e-02]\n",
      " [-5.15533079e-02  3.79980150e-01]\n",
      " [-4.39563394e-01  1.05257244e-02]\n",
      " [ 1.09041672e-01 -1.26023043e-01]\n",
      " [-1.67351589e-01  5.31793658e-03]\n",
      " [ 1.12915055e-01 -1.61599301e-01]\n",
      " [-4.60193648e-01 -2.96645496e-03]\n",
      " [ 2.99849061e-04 -7.77524869e-02]\n",
      " [-2.96851953e-01  3.62193764e-01]\n",
      " [-5.84744853e-01  3.64993781e-01]\n",
      " [-3.59678243e-01 -8.08273134e-03]\n",
      " [-3.59989100e-01 -5.31747161e-02]\n",
      " [-5.99881401e-03 -2.17799129e-02]] \n",
      "\n",
      "\n",
      "# 2\n",
      "my size:  3\n",
      "prev size:  32\n",
      "w:  [[ 5.74698289e-01  9.35642321e-02 -2.30351239e-01 -9.08807968e-02\n",
      "  -7.45052862e-01 -2.40322252e-01  6.01246066e-01  1.14594402e-01\n",
      "   5.27731369e-01 -1.09599691e-01  4.00723169e-01  6.22442487e-01\n",
      "   6.55052531e-01 -3.96909035e-01 -8.68760956e-02  9.19375286e-02\n",
      "   2.67638015e-01 -1.09972403e-01  3.42029549e-02  1.24166162e-01\n",
      "   4.73617804e-01 -2.80770652e-04 -3.65113107e-03 -2.57929389e-02\n",
      "  -7.07945142e-02 -2.36827920e-02  3.60585671e-01  2.02447674e-01\n",
      "  -9.59907511e-02 -5.19170045e-04  1.55732244e-01  3.97861822e-01]\n",
      " [ 6.32583966e-01 -1.05553663e-01 -2.05105177e-01  1.43622508e-01\n",
      "  -5.26334662e-01 -4.44075783e-01  5.29247932e-01  3.93955861e-01\n",
      "   6.07767838e-01 -5.29541331e-01  3.00323399e-01 -1.03701973e-02\n",
      "   4.82892459e-02 -1.10900150e-01  1.27378165e-02 -2.97306056e-01\n",
      "   3.86168793e-01  5.54629979e-01  1.83879269e-01 -2.46922988e-01\n",
      "   8.74412653e-02 -6.25190225e-02 -7.38144426e-02  7.82602906e-01\n",
      "  -1.71861645e-01  3.37283689e-01  1.24579377e-01  4.50723331e-02\n",
      "   3.53133699e-01  3.87271380e-02  8.62933444e-02 -2.03356113e-01]\n",
      " [-1.49777956e-01  2.07039986e-03  3.08931663e-01  3.72750429e-01\n",
      "  -6.31240859e-01 -1.00445876e-03  2.57734675e-01  4.00565796e-01\n",
      "   7.14136557e-02 -6.55519218e-01  8.04635514e-02  2.73963447e-01\n",
      "   4.21737053e-01  1.86627230e-01  3.34555717e-02  3.74562008e-01\n",
      "   3.27115416e-01  3.51773380e-01 -8.07057991e-02 -3.56894270e-01\n",
      "  -7.21965058e-02  3.59135553e-01 -1.02487277e-01  7.29241262e-01\n",
      "  -1.20999052e-01  1.35839275e-01  1.37602004e-01 -1.79590579e-01\n",
      "  -3.47136940e-01  3.40643173e-01  4.23985410e-01 -9.55233451e-02]] \n",
      "\n",
      "b:  [[ 5.74698289e-01  9.35642321e-02 -2.30351239e-01 -9.08807968e-02\n",
      "  -7.45052862e-01 -2.40322252e-01  6.01246066e-01  1.14594402e-01\n",
      "   5.27731369e-01 -1.09599691e-01  4.00723169e-01  6.22442487e-01\n",
      "   6.55052531e-01 -3.96909035e-01 -8.68760956e-02  9.19375286e-02\n",
      "   2.67638015e-01 -1.09972403e-01  3.42029549e-02  1.24166162e-01\n",
      "   4.73617804e-01 -2.80770652e-04 -3.65113107e-03 -2.57929389e-02\n",
      "  -7.07945142e-02 -2.36827920e-02  3.60585671e-01  2.02447674e-01\n",
      "  -9.59907511e-02 -5.19170045e-04  1.55732244e-01  3.97861822e-01]\n",
      " [ 6.32583966e-01 -1.05553663e-01 -2.05105177e-01  1.43622508e-01\n",
      "  -5.26334662e-01 -4.44075783e-01  5.29247932e-01  3.93955861e-01\n",
      "   6.07767838e-01 -5.29541331e-01  3.00323399e-01 -1.03701973e-02\n",
      "   4.82892459e-02 -1.10900150e-01  1.27378165e-02 -2.97306056e-01\n",
      "   3.86168793e-01  5.54629979e-01  1.83879269e-01 -2.46922988e-01\n",
      "   8.74412653e-02 -6.25190225e-02 -7.38144426e-02  7.82602906e-01\n",
      "  -1.71861645e-01  3.37283689e-01  1.24579377e-01  4.50723331e-02\n",
      "   3.53133699e-01  3.87271380e-02  8.62933444e-02 -2.03356113e-01]\n",
      " [-1.49777956e-01  2.07039986e-03  3.08931663e-01  3.72750429e-01\n",
      "  -6.31240859e-01 -1.00445876e-03  2.57734675e-01  4.00565796e-01\n",
      "   7.14136557e-02 -6.55519218e-01  8.04635514e-02  2.73963447e-01\n",
      "   4.21737053e-01  1.86627230e-01  3.34555717e-02  3.74562008e-01\n",
      "   3.27115416e-01  3.51773380e-01 -8.07057991e-02 -3.56894270e-01\n",
      "  -7.21965058e-02  3.59135553e-01 -1.02487277e-01  7.29241262e-01\n",
      "  -1.20999052e-01  1.35839275e-01  1.37602004e-01 -1.79590579e-01\n",
      "  -3.47136940e-01  3.40643173e-01  4.23985410e-01 -9.55233451e-02]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_dqn.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ea8963d-2e57-46f6-b2ba-35c481ea6423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME:  noname  ( 3 )\n",
      "# 0\n",
      "IN LAYER\n",
      "size:  2\n",
      "\n",
      "# 1\n",
      "my size:  32\n",
      "prev size:  2\n",
      "w:  [[-2.72965090e-01  4.65795556e-03]\n",
      " [ 4.39312084e-02 -5.87615344e-02]\n",
      " [ 1.51004116e-02  1.53689642e-01]\n",
      " [-8.68260302e-02  1.55476522e-01]\n",
      " [-1.37891000e-01  3.75900522e-01]\n",
      " [-2.02415540e-01  2.07961092e-01]\n",
      " [-1.95920366e-01  2.72990630e-03]\n",
      " [-1.71192271e-01  4.17900883e-01]\n",
      " [-4.47059298e-01  3.61449817e-03]\n",
      " [ 1.70041461e-01 -1.06982520e-01]\n",
      " [ 1.10903454e-01  4.76861679e-02]\n",
      " [-4.77833700e-01  1.74715194e-03]\n",
      " [-2.72444800e-01  1.01057440e-02]\n",
      " [ 1.62759542e-01 -6.13162779e-02]\n",
      " [ 1.39703770e-01 -1.25945232e-01]\n",
      " [-6.17570436e-01  3.90188131e-01]\n",
      " [-7.52195119e-01  3.09538143e-02]\n",
      " [-7.78831518e-02 -7.25747210e-02]\n",
      " [-7.95239025e-02 -2.14568762e-02]\n",
      " [-1.26090495e-01  9.22705116e-02]\n",
      " [-5.15533079e-02  3.79980150e-01]\n",
      " [-4.39563394e-01  1.05257244e-02]\n",
      " [ 1.09041672e-01 -1.26023043e-01]\n",
      " [-1.67351589e-01  5.31793658e-03]\n",
      " [ 1.12915055e-01 -1.61599301e-01]\n",
      " [-4.60193648e-01 -2.96645496e-03]\n",
      " [ 2.99849061e-04 -7.77524869e-02]\n",
      " [-2.96851953e-01  3.62193764e-01]\n",
      " [-5.84744853e-01  3.64993781e-01]\n",
      " [-3.59678243e-01 -8.08273134e-03]\n",
      " [-3.59989100e-01 -5.31747161e-02]\n",
      " [-5.99881401e-03 -2.17799129e-02]] \n",
      "\n",
      "b:  [[-2.72965090e-01  4.65795556e-03]\n",
      " [ 4.39312084e-02 -5.87615344e-02]\n",
      " [ 1.51004116e-02  1.53689642e-01]\n",
      " [-8.68260302e-02  1.55476522e-01]\n",
      " [-1.37891000e-01  3.75900522e-01]\n",
      " [-2.02415540e-01  2.07961092e-01]\n",
      " [-1.95920366e-01  2.72990630e-03]\n",
      " [-1.71192271e-01  4.17900883e-01]\n",
      " [-4.47059298e-01  3.61449817e-03]\n",
      " [ 1.70041461e-01 -1.06982520e-01]\n",
      " [ 1.10903454e-01  4.76861679e-02]\n",
      " [-4.77833700e-01  1.74715194e-03]\n",
      " [-2.72444800e-01  1.01057440e-02]\n",
      " [ 1.62759542e-01 -6.13162779e-02]\n",
      " [ 1.39703770e-01 -1.25945232e-01]\n",
      " [-6.17570436e-01  3.90188131e-01]\n",
      " [-7.52195119e-01  3.09538143e-02]\n",
      " [-7.78831518e-02 -7.25747210e-02]\n",
      " [-7.95239025e-02 -2.14568762e-02]\n",
      " [-1.26090495e-01  9.22705116e-02]\n",
      " [-5.15533079e-02  3.79980150e-01]\n",
      " [-4.39563394e-01  1.05257244e-02]\n",
      " [ 1.09041672e-01 -1.26023043e-01]\n",
      " [-1.67351589e-01  5.31793658e-03]\n",
      " [ 1.12915055e-01 -1.61599301e-01]\n",
      " [-4.60193648e-01 -2.96645496e-03]\n",
      " [ 2.99849061e-04 -7.77524869e-02]\n",
      " [-2.96851953e-01  3.62193764e-01]\n",
      " [-5.84744853e-01  3.64993781e-01]\n",
      " [-3.59678243e-01 -8.08273134e-03]\n",
      " [-3.59989100e-01 -5.31747161e-02]\n",
      " [-5.99881401e-03 -2.17799129e-02]] \n",
      "\n",
      "\n",
      "# 2\n",
      "my size:  3\n",
      "prev size:  32\n",
      "w:  [[ 5.74698289e-01  9.35642321e-02 -2.30351239e-01 -9.08807968e-02\n",
      "  -7.45052862e-01 -2.40322252e-01  6.01246066e-01  1.14594402e-01\n",
      "   5.27731369e-01 -1.09599691e-01  4.00723169e-01  6.22442487e-01\n",
      "   6.55052531e-01 -3.96909035e-01 -8.68760956e-02  9.19375286e-02\n",
      "   2.67638015e-01 -1.09972403e-01  3.42029549e-02  1.24166162e-01\n",
      "   4.73617804e-01 -2.80770652e-04 -3.65113107e-03 -2.57929389e-02\n",
      "  -7.07945142e-02 -2.36827920e-02  3.60585671e-01  2.02447674e-01\n",
      "  -9.59907511e-02 -5.19170045e-04  1.55732244e-01  3.97861822e-01]\n",
      " [ 6.32583966e-01 -1.05553663e-01 -2.05105177e-01  1.43622508e-01\n",
      "  -5.26334662e-01 -4.44075783e-01  5.29247932e-01  3.93955861e-01\n",
      "   6.07767838e-01 -5.29541331e-01  3.00323399e-01 -1.03701973e-02\n",
      "   4.82892459e-02 -1.10900150e-01  1.27378165e-02 -2.97306056e-01\n",
      "   3.86168793e-01  5.54629979e-01  1.83879269e-01 -2.46922988e-01\n",
      "   8.74412653e-02 -6.25190225e-02 -7.38144426e-02  7.82602906e-01\n",
      "  -1.71861645e-01  3.37283689e-01  1.24579377e-01  4.50723331e-02\n",
      "   3.53133699e-01  3.87271380e-02  8.62933444e-02 -2.03356113e-01]\n",
      " [-1.49777956e-01  2.07039986e-03  3.08931663e-01  3.72750429e-01\n",
      "  -6.31240859e-01 -1.00445876e-03  2.57734675e-01  4.00565796e-01\n",
      "   7.14136557e-02 -6.55519218e-01  8.04635514e-02  2.73963447e-01\n",
      "   4.21737053e-01  1.86627230e-01  3.34555717e-02  3.74562008e-01\n",
      "   3.27115416e-01  3.51773380e-01 -8.07057991e-02 -3.56894270e-01\n",
      "  -7.21965058e-02  3.59135553e-01 -1.02487277e-01  7.29241262e-01\n",
      "  -1.20999052e-01  1.35839275e-01  1.37602004e-01 -1.79590579e-01\n",
      "  -3.47136940e-01  3.40643173e-01  4.23985410e-01 -9.55233451e-02]] \n",
      "\n",
      "b:  [[ 5.74698289e-01  9.35642321e-02 -2.30351239e-01 -9.08807968e-02\n",
      "  -7.45052862e-01 -2.40322252e-01  6.01246066e-01  1.14594402e-01\n",
      "   5.27731369e-01 -1.09599691e-01  4.00723169e-01  6.22442487e-01\n",
      "   6.55052531e-01 -3.96909035e-01 -8.68760956e-02  9.19375286e-02\n",
      "   2.67638015e-01 -1.09972403e-01  3.42029549e-02  1.24166162e-01\n",
      "   4.73617804e-01 -2.80770652e-04 -3.65113107e-03 -2.57929389e-02\n",
      "  -7.07945142e-02 -2.36827920e-02  3.60585671e-01  2.02447674e-01\n",
      "  -9.59907511e-02 -5.19170045e-04  1.55732244e-01  3.97861822e-01]\n",
      " [ 6.32583966e-01 -1.05553663e-01 -2.05105177e-01  1.43622508e-01\n",
      "  -5.26334662e-01 -4.44075783e-01  5.29247932e-01  3.93955861e-01\n",
      "   6.07767838e-01 -5.29541331e-01  3.00323399e-01 -1.03701973e-02\n",
      "   4.82892459e-02 -1.10900150e-01  1.27378165e-02 -2.97306056e-01\n",
      "   3.86168793e-01  5.54629979e-01  1.83879269e-01 -2.46922988e-01\n",
      "   8.74412653e-02 -6.25190225e-02 -7.38144426e-02  7.82602906e-01\n",
      "  -1.71861645e-01  3.37283689e-01  1.24579377e-01  4.50723331e-02\n",
      "   3.53133699e-01  3.87271380e-02  8.62933444e-02 -2.03356113e-01]\n",
      " [-1.49777956e-01  2.07039986e-03  3.08931663e-01  3.72750429e-01\n",
      "  -6.31240859e-01 -1.00445876e-03  2.57734675e-01  4.00565796e-01\n",
      "   7.14136557e-02 -6.55519218e-01  8.04635514e-02  2.73963447e-01\n",
      "   4.21737053e-01  1.86627230e-01  3.34555717e-02  3.74562008e-01\n",
      "   3.27115416e-01  3.51773380e-01 -8.07057991e-02 -3.56894270e-01\n",
      "  -7.21965058e-02  3.59135553e-01 -1.02487277e-01  7.29241262e-01\n",
      "  -1.20999052e-01  1.35839275e-01  1.37602004e-01 -1.79590579e-01\n",
      "  -3.47136940e-01  3.40643173e-01  4.23985410e-01 -9.55233451e-02]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_dqn.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "961f4d8e-fac6-4220-9687-ded89638b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = [[10, 11], [6, 6], [9, 14], [7, 10], [8, 12], [7, 10], [7, 9], [9, 10], [8, 9], [8, 9], [9, 12], [7, 8], [5, 10], [7, 10], [10, 12], [9, 12], [7, 9], [8, 11], [7, 9], [11, 9], [7, 7], [10, 9], [8, 11], [10, 11], [7, 13], [9, 10], [8, 9], [8, 9], [8, 10], [8, 10], [9, 11], [6, 16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f9495f-2c6b-4452-96a5-f551096145ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b85271-fa23-4b2b-8c9a-a577ce016c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "c78fedb0-800f-495b-b18b-2e3fa0acc238",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
