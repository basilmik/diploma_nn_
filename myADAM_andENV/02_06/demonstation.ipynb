{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e71df1-03b0-4aac-a5b9-431ddd4e4e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from gymnasium) (1.26.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from gymnasium) (4.8.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages (from gymnasium) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\program files (x86)\\microsoft visual studio\\shared\\python39_64\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\basil\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad4b8fe-efc9-49c3-852e-d7a0afd40543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 [2 2 2 3]\n",
      "Episode 1000 Epsilon 0.7840000000000238\n",
      "Episode 2000 Epsilon 0.2840000000000549\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "0 [2 2 2 3]\n",
      "Episode 1000 Epsilon 0.7540000000000271\n",
      "Episode 2000 Epsilon 0.25400000000005485\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "1 [2 2 2 3]\n",
      "Episode 1000 Epsilon 0.5510000000000495\n",
      "Episode 2000 Epsilon 0.05100000000005467\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "2 [2 2 2 3]\n",
      "Episode 1000 Epsilon 0.7765000000000246\n",
      "Episode 2000 Epsilon 0.27650000000005487\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "0 [2 3 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 1\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "1 [2 3 2 3]\n",
      "Episode 1000 Epsilon 0.7955000000000225\n",
      "Episode 2000 Epsilon 0.2955000000000549\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "2 [2 3 2 3]\n",
      "Episode 1000 Epsilon 0.7230000000000305\n",
      "Best rewards so far: -188.0\n",
      "Best rewards so far: -187.0\n",
      "Best rewards so far: -180.0\n",
      "Best rewards so far: -160.0\n",
      "Best rewards so far: -159.0\n",
      "Best rewards so far: -151.0\n",
      "Best rewards so far: -146.0\n",
      "Episode 2000 Epsilon 0.22300000000005482\n",
      "test_res  100.0\n",
      "medium_reward  -126.04\n",
      "success shape:  [2 3 2 3]\n",
      "1\n",
      "0 [2 2 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 1\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "0 [2 2 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 0.773500000000025\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "1 [2 2 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 0.7535000000000271\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "2 [2 2 2 3]\n",
      "Episode 1000 Epsilon 0.9575000000000047\n",
      "Episode 2000 Epsilon 0.45750000000005503\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "0 [2 3 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 1\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "1 [2 3 2 3]\n",
      "Best rewards so far: -190.0\n",
      "Episode 1000 Epsilon 0.5625000000000482\n",
      "Best rewards so far: -187.0\n",
      "Best rewards so far: -155.0\n",
      "Best rewards so far: -152.0\n",
      "Best rewards so far: -149.0\n",
      "Best rewards so far: -144.0\n",
      "Best rewards so far: -118.0\n",
      "Episode 2000 Epsilon 0.06250000000005468\n",
      "test_res  97.0\n",
      "medium_reward  -119.16\n",
      "success shape:  [2 3 2 3]\n",
      "2\n",
      "0 [2 2 2 3]\n",
      "Episode 1000 Epsilon 0.6340000000000403\n",
      "Episode 2000 Epsilon 0.13400000000005474\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "0 [2 2 2 3]\n",
      "Episode 1000 Epsilon 0.6725000000000361\n",
      "Episode 2000 Epsilon 0.17250000000005478\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "1 [2 2 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 1\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "2 [2 2 2 3]\n",
      "Episode 1000 Epsilon 0.7695000000000254\n",
      "Episode 2000 Epsilon 0.26950000000005486\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "0 [2 3 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 0.7505000000000275\n",
      "test_res  5.0\n",
      "medium_reward  -199.9\n",
      "0 [2 3 2 3]\n",
      "Episode 1000 Epsilon 0.536500000000051\n",
      "Best rewards so far: -199.0\n",
      "Best rewards so far: -197.0\n",
      "Best rewards so far: -187.0\n",
      "Best rewards so far: -150.0\n",
      "Best rewards so far: -148.0\n",
      "Best rewards so far: -143.0\n",
      "Best rewards so far: -139.0\n",
      "Best rewards so far: -123.0\n",
      "Best rewards so far: -121.0\n",
      "Episode 2000 Epsilon 0.036500000000054655\n",
      "test_res  24.0\n",
      "medium_reward  -181.14\n",
      "0 [2 3 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 0.6775000000000355\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "1 [2 3 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 1\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "2 [2 3 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 0.9890000000000012\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "0 [2 3 3 3]\n",
      "Episode 1000 Epsilon 0.6890000000000343\n",
      "Episode 2000 Epsilon 0.1890000000000548\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "1 [2 3 3 3]\n",
      "Episode 1000 Epsilon 0.809000000000021\n",
      "Episode 2000 Epsilon 0.3090000000000549\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "2 [2 3 3 3]\n",
      "Episode 1000 Epsilon 0.8290000000000188\n",
      "Episode 2000 Epsilon 0.3290000000000549\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "0 [2 4 3 3]\n",
      "Episode 1000 Epsilon 0.5345000000000513\n",
      "Episode 2000 Epsilon 0.034500000000054654\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "1 [2 4 3 3]\n",
      "Episode 1000 Epsilon 0.5475000000000498\n",
      "Episode 2000 Epsilon 0.047500000000054665\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "2 [2 4 3 3]\n",
      "Episode 1000 Epsilon 0.8215000000000197\n",
      "Episode 2000 Epsilon 0.3215000000000549\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "search falied\n",
      "3\n",
      "0 [2 2 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 0.9215000000000086\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "0 [2 2 2 3]\n",
      "Episode 1000 Epsilon 0.6685000000000365\n",
      "Best rewards so far: -169.0\n",
      "Best rewards so far: -159.0\n",
      "Best rewards so far: -158.0\n",
      "Best rewards so far: -155.0\n",
      "Best rewards so far: -152.0\n",
      "Best rewards so far: -125.0\n",
      "Episode 2000 Epsilon 0.16850000000005477\n",
      "test_res  78.0\n",
      "medium_reward  -139.24\n",
      "0 [2 2 2 3]\n",
      "Episode 1000 Epsilon 0.5755000000000468\n",
      "Best rewards so far: -196.0\n",
      "Best rewards so far: -182.0\n",
      "Best rewards so far: -165.0\n",
      "Best rewards so far: -157.0\n",
      "Best rewards so far: -151.0\n",
      "Best rewards so far: -119.0\n",
      "Best rewards so far: -117.0\n",
      "Best rewards so far: -116.0\n",
      "Episode 2000 Epsilon 0.07550000000005469\n",
      "test_res  100.0\n",
      "medium_reward  -107.87\n",
      "success shape:  [2 2 2 3]\n",
      "4\n",
      "0 [2 2 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 0.5315000000000516\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "0 [2 2 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 0.6960000000000335\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "1 [2 2 2 3]\n",
      "Episode 1000 Epsilon 0.5635000000000481\n",
      "Episode 2000 Epsilon 0.06350000000005468\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "2 [2 2 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 1\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "0 [2 3 2 3]\n",
      "Episode 1000 Epsilon 0.8065000000000213\n",
      "Episode 2000 Epsilon 0.3065000000000549\n",
      "test_res  0.0\n",
      "medium_reward  -200.0\n",
      "1 [2 3 2 3]\n",
      "Episode 1000 Epsilon 1\n",
      "Episode 2000 Epsilon 0.500500000000055\n",
      "test_res  100.0\n",
      "medium_reward  -160.51\n",
      "success shape:  [2 3 2 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import import_ipynb\n",
    "from dqn_5 import DQN\n",
    "from dqn_5 import DQN_search\n",
    "\n",
    "\n",
    "N_TESTS = 5\n",
    "s_res_cnt = 0\n",
    "for i in range(N_TESTS):\n",
    "    print(i)\n",
    "    search = DQN_search(dqn_model = DQN(game_name = 'MountainCar-v0', mini_batch_size = 64, num_divisions = 50))\n",
    "    atypes = ['', 'ReLU', 'ReLU', 'Linear']\n",
    "    search.set_a_type_array(atypes)\n",
    "    search.set_lr(0.001)\n",
    "    start_net_shape = np.array([2, 2, 2, 3])\n",
    "    shape_steps = np.array([[0, 1, 0, 0], [0, 0, 1, 0]])\n",
    "    final_shape = np.array([2, 4, 4, 3])\n",
    "    n_models = 3\n",
    "    TSR = 95\n",
    "    test_res, shape, good_policy = search.search(n_models, TSR, epochs = 2000, \n",
    "                                                 start_shape = np.array(start_net_shape), \n",
    "                                                 shape_steps = shape_steps,\n",
    "                                                 final_shape = final_shape,\n",
    "                                                 adaptive_n_models = True,\n",
    "                                                 min_best_result = -550\n",
    "                                                )\n",
    "    if (test_res!= False):\n",
    "        s_res_cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89750986-5296-48d8-b815-ecfa0bc6c48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0\n"
     ]
    }
   ],
   "source": [
    "print(100.0*s_res_cnt/N_TESTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bd793-821e-4e92-bf30-a0bc80e2267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (test_res!= False):\n",
    "    model_ = DQN(game_name = 'MountainCar-v0', mini_batch_size = 64, num_divisions = 50)\n",
    "    res = model_.test(good_policy, 10, render = True)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a83b43-8c50-4380-aac4-9b8e8a693674",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065856ab-2936-47aa-abfd-7ac17629eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_space = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a8f9f7-1096-4712-9611-84514e46f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_space[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6dba9b-df9f-42bd-bbb2-1e2b3e14d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87fe04b-3f7c-429d-a4e4-94c6febe55a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "0\n",
    "0 [2 2 2 3]\n",
    "Episode 1000 Epsilon 0.782500000000024\n",
    "Episode 2000 Epsilon 0.2825000000000549\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 2 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 2 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 2 2 3]\n",
    "Episode 1000 Epsilon 0.964000000000004\n",
    "Best rewards so far: -168.0\n",
    "Episode 2000 Epsilon 0.46400000000005504\n",
    "test_res  100.0\n",
    "medium_reward  -136.43\n",
    "success shape:  [2 2 2 3]\n",
    "1\n",
    "0 [2 2 2 3]\n",
    "Episode 1000 Epsilon 0.6615000000000373\n",
    "Episode 2000 Epsilon 0.16150000000005477\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 2 2 3]\n",
    "Episode 1000 Epsilon 0.6120000000000427\n",
    "Episode 2000 Epsilon 0.11200000000005472\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 2 2 3]\n",
    "Episode 1000 Epsilon 0.6180000000000421\n",
    "Episode 2000 Epsilon 0.11800000000005473\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 2 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 0.5425000000000504\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 3 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 0.6220000000000416\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 3 2 3]\n",
    "Episode 1000 Epsilon 0.7750000000000248\n",
    "Episode 2000 Epsilon 0.27500000000005487\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 3 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 3 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 3 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 3 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 4 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 4 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 4 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Best rewards so far: -182.0\n",
    "Best rewards so far: -170.0\n",
    "Best rewards so far: -164.0\n",
    "Episode 2000 Epsilon 0.519000000000053\n",
    "test_res  100.0\n",
    "medium_reward  -136.35\n",
    "success shape:  [2 4 3 3]\n",
    "2\n",
    "0 [2 2 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 2 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 0.9620000000000042\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 2 2 3]\n",
    "Episode 1000 Epsilon 0.9585000000000046\n",
    "Episode 2000 Epsilon 0.45850000000005503\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 2 2 3]\n",
    "Episode 1000 Epsilon 0.5345000000000513\n",
    "Episode 2000 Epsilon 0.034500000000054654\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 3 2 3]\n",
    "Episode 1000 Epsilon 0.6345000000000403\n",
    "Best rewards so far: -195.0\n",
    "Best rewards so far: -193.0\n",
    "Episode 2000 Epsilon 0.13450000000005474\n",
    "test_res  40.0\n",
    "medium_reward  -196.67\n",
    "0 [2 3 2 3]\n",
    "Episode 1000 Epsilon 0.5030000000000547\n",
    "Best rewards so far: -199.0\n",
    "Best rewards so far: -179.0\n",
    "Best rewards so far: -136.0\n",
    "Best rewards so far: -131.0\n",
    "Best rewards so far: -124.0\n",
    "Episode 2000 Epsilon 0.01\n",
    "test_res  53.0\n",
    "medium_reward  -164.39\n",
    "0 [2 3 2 3]\n",
    "Episode 1000 Epsilon 0.5270000000000521\n",
    "Episode 2000 Epsilon 0.027000000000054647\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 3 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 3 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 3 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 0.6690000000000365\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 3 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 3 3 3]\n",
    "Episode 1000 Epsilon 0.7450000000000281\n",
    "Best rewards so far: -187.0\n",
    "Best rewards so far: -162.0\n",
    "Best rewards so far: -150.0\n",
    "Best rewards so far: -121.0\n",
    "Episode 2000 Epsilon 0.24500000000005484\n",
    "test_res  37.0\n",
    "medium_reward  -172.02\n",
    "0 [2 4 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 4 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 4 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 0.891000000000012\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "search falied\n",
    "3\n",
    "0 [2 2 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 2 2 3]\n",
    "Episode 1000 Epsilon 0.536500000000051\n",
    "Episode 2000 Epsilon 0.036500000000054655\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 2 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 2 2 3]\n",
    "Episode 1000 Epsilon 0.7420000000000284\n",
    "Episode 2000 Epsilon 0.24200000000005484\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 3 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 3 2 3]\n",
    "Episode 1000 Epsilon 0.7160000000000313\n",
    "Episode 2000 Epsilon 0.21600000000005481\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 3 2 3]\n",
    "Episode 1000 Epsilon 0.7195000000000309\n",
    "Best rewards so far: -181.0\n",
    "Best rewards so far: -169.0\n",
    "Best rewards so far: -134.0\n",
    "Best rewards so far: -132.0\n",
    "Best rewards so far: -124.0\n",
    "Best rewards so far: -123.0\n",
    "Episode 2000 Epsilon 0.21950000000005482\n",
    "test_res  97.0\n",
    "medium_reward  -125.5\n",
    "success shape:  [2 3 2 3]\n",
    "4\n",
    "0 [2 2 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 0.5965000000000444\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 2 2 3]\n",
    "Episode 1000 Epsilon 0.5725000000000471\n",
    "Episode 2000 Epsilon 0.07250000000005469\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 2 2 3]\n",
    "Episode 1000 Epsilon 0.7585000000000266\n",
    "Episode 2000 Epsilon 0.25850000000005485\n",
    "test_res  58.0\n",
    "medium_reward  -169.06\n",
    "1 [2 2 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 0.7660000000000258\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 2 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 3 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 3 2 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 0.9755000000000027\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 3 2 3]\n",
    "Episode 1000 Epsilon 0.6440000000000392\n",
    "Episode 2000 Epsilon 0.14400000000005475\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 3 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Best rewards so far: -188.0\n",
    "Episode 2000 Epsilon 0.5205000000000528\n",
    "test_res  94.0\n",
    "medium_reward  -138.88\n",
    "0 [2 3 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 1\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "1 [2 3 3 3]\n",
    "Episode 1000 Epsilon 1\n",
    "Episode 2000 Epsilon 0.6310000000000406\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "2 [2 3 3 3]\n",
    "Episode 1000 Epsilon 0.5015000000000549\n",
    "Episode 2000 Epsilon 0.01\n",
    "test_res  0.0\n",
    "medium_reward  -200.0\n",
    "0 [2 4 3 3]\n",
    "Episode 1000 Epsilon 0.5135000000000536\n",
    "Best rewards so far: -190.0\n",
    "Best rewards so far: -166.0\n",
    "Best rewards so far: -150.0\n",
    "Best rewards so far: -120.0\n",
    "Best rewards so far: -112.0\n",
    "Episode 2000 Epsilon 0.013500000000054635\n",
    "test_res  100.0\n",
    "medium_reward  -125.5\n",
    "success shape:  [2 4 3 3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
